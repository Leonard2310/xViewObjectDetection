{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":10182328,"datasetId":6242793,"databundleVersionId":10471001}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library import","metadata":{}},{"cell_type":"code","source":"import os\nimport subprocess\nimport time\n\nimport yaml\nfrom sklearn.model_selection import GroupKFold\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nfrom tqdm import tqdm\nimport torch.nn as nn\n\nfrom pathlib import Path\nimport json\nfrom collections import defaultdict, Counter\nimport random\nimport random\nimport shutil\nfrom tqdm import tqdm\nimport zipfile\nfrom collections import Counter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T02:11:54.521717Z","iopub.execute_input":"2025-01-03T02:11:54.522067Z","iopub.status.idle":"2025-01-03T02:11:58.570906Z","shell.execute_reply.started":"2025-01-03T02:11:54.522023Z","shell.execute_reply":"2025-01-03T02:11:58.570196Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"%pip install ultralytics\nimport ultralytics\nultralytics.checks()\nfrom ultralytics import YOLO","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T02:11:58.572096Z","iopub.execute_input":"2025-01-03T02:11:58.572446Z","iopub.status.idle":"2025-01-03T02:12:09.446305Z","shell.execute_reply.started":"2025-01-03T02:11:58.572419Z","shell.execute_reply":"2025-01-03T02:12:09.445560Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.57 ðŸš€ Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\nSetup complete âœ… (4 CPUs, 31.4 GB RAM, 6037.6/8062.4 GB disk)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Path","metadata":{}},{"cell_type":"code","source":"COCO_JSON_NM = 'COCO_annotations_new.json'\nOUT_COCO_JSON_NM = 'mod_COCO_annotations.json'\nOUT_IMAGE_FLDR_NM = 'images'\nTRAIN_NM = 'train'\nVAL_NM = 'val'\nTEST_NM = 'test'\nLABEL_NM = 'labels'\nYAML = 'dataset.yaml'\nRANDOM_SEED = 2023\n\nin_dataset_pth = Path('/kaggle/input/our-xview-dataset')\nyolo_dataset_pth = Path('/kaggle/input/yolodataset-xview')\nout_dataset_pth = Path('/kaggle/working/')\nimg_fldr = Path(f'/kaggle/input/our-xview-dataset/{OUT_IMAGE_FLDR_NM}')\n\ncoco_json_pth = in_dataset_pth / COCO_JSON_NM\nnew_coco_json_pth = out_dataset_pth / OUT_COCO_JSON_NM\n\ntrain_img = yolo_dataset_pth / TRAIN_NM / OUT_IMAGE_FLDR_NM\nval_img = yolo_dataset_pth / VAL_NM / OUT_IMAGE_FLDR_NM\ntest_img = yolo_dataset_pth / TEST_NM / OUT_IMAGE_FLDR_NM\ntrain_txt = yolo_dataset_pth / TRAIN_NM / LABEL_NM\nval_txt = yolo_dataset_pth / VAL_NM / LABEL_NM \ntest_txt = yolo_dataset_pth / TEST_NM / LABEL_NM  \ndataset_yaml = yolo_dataset_pth / YAML","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T02:12:09.447832Z","iopub.execute_input":"2025-01-03T02:12:09.448314Z","iopub.status.idle":"2025-01-03T02:12:09.454726Z","shell.execute_reply.started":"2025-01-03T02:12:09.448282Z","shell.execute_reply":"2025-01-03T02:12:09.453480Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Pulizia dell'output per cartelle specifiche\ndef clean_output(output_dir):\n    if output_dir.exists() and output_dir.is_dir():\n        for item in output_dir.iterdir():\n            if item.is_dir():\n                shutil.rmtree(item)  # Rimuove la sotto-cartella\n            else:\n                item.unlink()  # Rimuove il file\n        print(f\"Cartella {output_dir} pulita.\")\n    else:\n        print(f\"Cartella {output_dir} non trovata. Nessuna azione necessaria.\")\n\n# Pulisce la cartella di output prima di avviare il processo\nclean_output(out_dataset_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T02:12:09.455817Z","iopub.execute_input":"2025-01-03T02:12:09.456073Z","iopub.status.idle":"2025-01-03T02:12:09.466900Z","shell.execute_reply.started":"2025-01-03T02:12:09.456048Z","shell.execute_reply":"2025-01-03T02:12:09.466030Z"}},"outputs":[{"name":"stdout","text":"Cartella /kaggle/working pulita.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Utility","metadata":{}},{"cell_type":"code","source":"def load_json(file_path):\n    \"\"\"\n    Carica un file JSON dal percorso specificato.\n\n    :param file_path: Percorso al file JSON da caricare.\n    :return: Dati contenuti nel file JSON (come dizionario o lista).\n    \"\"\"\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T02:12:09.477217Z","iopub.execute_input":"2025-01-03T02:12:09.477457Z","iopub.status.idle":"2025-01-03T02:12:09.486040Z","shell.execute_reply.started":"2025-01-03T02:12:09.477433Z","shell.execute_reply":"2025-01-03T02:12:09.485359Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# COCO Preprocessing","metadata":{}},{"cell_type":"code","source":"def process_custom_coco_json(input_path, output_path):\n    \"\"\"\n    Funzione per processare un JSON COCO in formato personalizzato.\n    \"\"\"\n    # Leggi il JSON dal file di input\n    data = load_json(input_path)\n\n    # Ottieni e correggi il formato delle categorie\n    raw_categories = data.get('categories', [])\n    categories = []\n \n    for category in tqdm(raw_categories, desc=\"Processing Categories\"):\n        for id_str, name in category.items():\n            try:\n                categories.append({\"id\": int(id_str), \"name\": name})\n            except ValueError:\n                print(f\"Errore nel parsing della categoria: {category}\")\n \n    # Preprocessa le annotazioni in un dizionario per immagini\n    image_annotations_dict = {}\n    for annotation in tqdm(data.get('annotations', []), desc=\"Building Image Annotations Dictionary\"):\n        image_id = annotation['image_id']\n        if image_id not in image_annotations_dict:\n            image_annotations_dict[image_id] = []\n        image_annotations_dict[image_id].append(annotation)\n \n    # Elenco di annotazioni da mantenere (solo quelle valide)\n    valid_annotations = []\n    annotations_to_remove = set()\n \n    # Controllo dei bounding box\n    for annotation in tqdm(data.get('annotations', []), desc=\"Processing Annotations\"):\n        \n        # Converte il formato del bbox\n        if isinstance(annotation['bbox'], str):\n            annotation['bbox'] = json.loads(annotation['bbox'])\n        \n        x, y, width, height = annotation['bbox']\n        xmin, xmax = x, x + width\n        ymin, ymax = y, y + height\n        \n        # Verifica che xmin < xmax e ymin < ymax, e che la larghezza e altezza siano sufficienti\n        if xmin >= xmax or ymin >= ymax or width <= 10 or height <= 10:\n            annotations_to_remove.add(annotation['id'])\n        else:\n            annotation['bbox'] = [xmin, ymin, xmax, ymax]\n            valid_annotations.append(annotation)\n \n    # Rimuovi le annotazioni non valide\n    data['annotations'] = valid_annotations\n \n    # Ordina le categorie per ID\n    categories = sorted(categories, key=lambda x: x['id'])\n    \n    # Aggiorna le categorie nel JSON\n    data['categories'] = categories\n\n \n    # Scrivi il JSON modificato nel file di output\n    with open(output_path, 'w') as f:\n        json.dump(data, f, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:54:31.052160Z","iopub.execute_input":"2025-01-02T23:54:31.052533Z","iopub.status.idle":"2025-01-02T23:54:31.066678Z","shell.execute_reply.started":"2025-01-02T23:54:31.052498Z","shell.execute_reply":"2025-01-02T23:54:31.065462Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"process_custom_coco_json(coco_json_pth, new_coco_json_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:54:31.067997Z","iopub.execute_input":"2025-01-02T23:54:31.068621Z","iopub.status.idle":"2025-01-02T23:54:46.296641Z","shell.execute_reply.started":"2025-01-02T23:54:31.068409Z","shell.execute_reply":"2025-01-02T23:54:46.295546Z"}},"outputs":[{"name":"stderr","text":"Processing Categories: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 61929.32it/s]\nBuilding Image Annotations Dictionary: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 669983/669983 [00:00<00:00, 1909198.08it/s]\nProcessing Annotations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 669983/669983 [00:04<00:00, 167462.72it/s]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### Category Check","metadata":{}},{"cell_type":"code","source":"def count_bounding_boxes(json_path):\n    \"\"\"\n    Conta il numero di bounding box per ogni categoria in un file COCO JSON.\n\n    Args:\n        json_path (str): Percorso del file JSON.\n\n    Returns:\n        list: Elenco di tuple con ID categoria, nome categoria e numero di bounding box.\n    \"\"\"\n    # Carica il file JSON\n    coco_data = load_json(json_path)\n\n    # Estrarre i dati principali\n    annotations = coco_data.get(\"annotations\", [])\n    categories = coco_data.get(\"categories\", [])\n\n    # Mappare id di categoria ai nomi delle categorie\n    category_id_to_name = {category[\"id\"]: category[\"name\"] for category in categories}\n\n    # Contare i bounding box per categoria\n    bbox_counts = defaultdict(int)\n    for annotation in annotations:\n        category_id = annotation[\"category_id\"]\n        bbox_counts[category_id] += 1\n\n    # Creare un elenco dei risultati\n    results = [\n        (cat_id, category_id_to_name.get(cat_id, \"Unknown\"), count)\n        for cat_id, count in bbox_counts.items()\n    ]\n    \n    # Ordinare i risultati in ordine decrescente per numero di bounding box\n    results.sort(key=lambda x: x[2], reverse=True)\n    \n    # Stampare i risultati\n    for cat_id, category_name, count in results:\n        print(f\"Categoria ID {cat_id} ('{category_name}'): {count} bounding box\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:54:46.297869Z","iopub.execute_input":"2025-01-02T23:54:46.298311Z","iopub.status.idle":"2025-01-02T23:54:46.306707Z","shell.execute_reply.started":"2025-01-02T23:54:46.298266Z","shell.execute_reply":"2025-01-02T23:54:46.305538Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"count_bounding_boxes(new_coco_json_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:54:46.310522Z","iopub.execute_input":"2025-01-02T23:54:46.311001Z","iopub.status.idle":"2025-01-02T23:54:49.180033Z","shell.execute_reply.started":"2025-01-02T23:54:46.310953Z","shell.execute_reply":"2025-01-02T23:54:49.179001Z"}},"outputs":[{"name":"stdout","text":"Categoria ID 6 ('Building'): 343313 bounding box\nCategoria ID 1 ('Passenger Vehicle'): 93827 bounding box\nCategoria ID 2 ('Truck'): 24582 bounding box\nCategoria ID 4 ('Maritime Vessel'): 5161 bounding box\nCategoria ID 5 ('Engineering Vehicle'): 4728 bounding box\nCategoria ID 9 ('Shipping Container'): 4558 bounding box\nCategoria ID 3 ('Railway Vehicle'): 3691 bounding box\nCategoria ID 8 ('Storage Tank'): 1743 bounding box\nCategoria ID 0 ('Aircraft'): 1561 bounding box\nCategoria ID 10 ('Pylon'): 415 bounding box\nCategoria ID 7 ('Helipad'): 136 bounding box\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# JSON to YOLO","metadata":{}},{"cell_type":"code","source":"def convert_json_to_yolo(json_path, images_dir, output_dir, input_dir, train_dir_out, val_dir_out, test_dir_out, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n    # Carica il file JSON\n    with open(json_path) as f:\n        data = json.load(f)\n\n    # Mappa le classi\n    class_mapping = {category['id']: category['name'] for category in data['categories']}\n    nc = len(class_mapping)  # Numero di classi\n\n    # Crea le cartelle per il dataset\n    train_images_dir = os.path.join(output_dir, 'train', 'images')\n    val_images_dir = os.path.join(output_dir, 'val', 'images')\n    test_images_dir = os.path.join(output_dir, 'test', 'images')\n\n    train_labels_dir = os.path.join(output_dir, 'train', 'labels')\n    val_labels_dir = os.path.join(output_dir, 'val', 'labels')\n    test_labels_dir = os.path.join(output_dir, 'test', 'labels')\n    \n    for dir_path in [train_images_dir, val_images_dir, test_images_dir, train_labels_dir, val_labels_dir, test_labels_dir]:\n        os.makedirs(dir_path, exist_ok=True)\n\n    # Dividi le immagini in training, validation, and test\n    images = data['images']\n    random.shuffle(images)\n    total_images = len(images)\n    \n    train_split = int(train_ratio * total_images)\n    val_split = int((train_ratio + val_ratio) * total_images)\n\n    train_images = images[:train_split]\n    val_images = images[train_split:val_split]\n    test_images = images[val_split:]\n\n    # Funzione per copiare le immagini in una cartella specifica\n    def copy_images(image_list, target_dir):\n        for image in tqdm(image_list, desc=f\"Copying images to {target_dir}\", unit=\"image\"):\n            src_path = os.path.join(images_dir, image['file_name'])\n            dst_path = os.path.join(target_dir, image['file_name'])\n            shutil.copy(src_path, dst_path)\n\n    # Copia le immagini nelle rispettive cartelle\n    copy_images(train_images, train_images_dir)\n    copy_images(val_images, val_images_dir)\n    copy_images(test_images, test_images_dir)\n\n    # Converte le annotazioni in formato YOLO e salva nei file di testo\n    def convert_annotations(image, annotations, target_dir):\n        image_id = image['id']\n        image_width = image['width']\n        image_height = image['height']\n        image_name = image['file_name']\n\n        label_file_path = os.path.join(target_dir, f\"{image_name.replace('.jpg', '.txt')}\")\n        label_dir = os.path.dirname(label_file_path)\n\n        # Crea la cartella se non esiste\n        os.makedirs(label_dir, exist_ok=True)\n\n        with open(label_file_path, 'w') as label_file:\n            for annotation in annotations:\n                if annotation['image_id'] == image_id:\n                    category_id = annotation['category_id']\n                    xmin, ymin, xmax, ymax = annotation['bbox']\n\n                    # Normalizza le coordinate\n                    x_center = (xmin + xmax) / 2 / image_width\n                    y_center = (ymin + ymax) / 2 / image_height\n                    width = (xmax - xmin) / image_width\n                    height = (ymax - ymin) / image_height\n\n                    # Scrivi nel file di annotazione\n                    label_file.write(f\"{category_id} {x_center} {y_center} {width} {height}\\n\")\n\n    # Converte le annotazioni per ogni immagine e le salva nelle cartelle appropriate\n    def process_images(image_list, target_dir, label_target_dir):\n        for image in tqdm(image_list, desc=f\"Converting annotations\", unit=\"image\"):\n            annotations = [annotation for annotation in data['annotations'] if annotation['image_id'] == image['id']]\n            convert_annotations(image, annotations, label_target_dir)\n\n    # Processa le immagini per training, validation e test\n    process_images(train_images, 'train', train_labels_dir)\n    process_images(val_images, 'val', val_labels_dir)\n    process_images(test_images, 'test', test_labels_dir)\n        \n    # Crea il file YAML per YOLO\n    yaml_content = f\"\"\"path: {input_dir}\ntrain: {train_dir_out}  # train images\nval: {val_dir_out}  # val images\ntest: {test_dir_out}  # test images\n\n# Classes\nnc: {nc}  # number of classes\nnames:\n\"\"\"\n    # Aggiungi le classi al file YAML\n    for idx, class_name in class_mapping.items():\n        yaml_content += f\"  {int(idx)}: {class_name}\\n\"  # Assicurati che l'indice sia numerico senza virgolette\n\n    # Scrivi il file YAML\n    with open(os.path.join(output_dir, 'dataset.yaml'), 'w') as yaml_file:\n        yaml_file.write(yaml_content.strip())\n\n    print(\"Conversione e split completati.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:54:49.182025Z","iopub.execute_input":"2025-01-02T23:54:49.182403Z","iopub.status.idle":"2025-01-02T23:54:49.198670Z","shell.execute_reply.started":"2025-01-02T23:54:49.182334Z","shell.execute_reply":"2025-01-02T23:54:49.197604Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"convert_json_to_yolo(\n    json_path=new_coco_json_pth,\n    images_dir=img_fldr,\n    output_dir=out_dataset_pth,\n    input_dir=yolo_dataset_pth,\n    train_dir_out=train_img,\n    val_dir_out=val_img,\n    test_dir_out=test_img,\n    train_ratio=0.8,\n    val_ratio=0.1,\n    test_ratio=0.1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:54:49.200221Z","iopub.execute_input":"2025-01-02T23:54:49.200703Z","iopub.status.idle":"2025-01-03T00:58:47.820800Z","shell.execute_reply.started":"2025-01-02T23:54:49.200654Z","shell.execute_reply":"2025-01-03T00:58:47.818741Z"}},"outputs":[{"name":"stderr","text":"Copying images to /kaggle/working/train/images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36712/36712 [05:46<00:00, 106.04image/s]\nCopying images to /kaggle/working/val/images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4589/4589 [00:43<00:00, 104.65image/s]\nCopying images to /kaggle/working/test/images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4590/4590 [00:43<00:00, 104.87image/s]\nConverting annotations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36712/36712 [45:12<00:00, 13.54image/s]\nConverting annotations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4589/4589 [05:34<00:00, 13.71image/s]\nConverting annotations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4590/4590 [05:54<00:00, 12.93image/s]\n","output_type":"stream"},{"name":"stdout","text":"Conversione e split completati.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Nome del file zip da creare\nzip_file_name = \"YOLO_dataset.zip\"\n\n# Elenco di file e cartelle da includere nello zip\nitems_to_zip = [\n    \"test\",\n    \"train\",\n    \"val\",\n    \"dataset.yaml\",\n]\n\n# Funzione per aggiungere file e cartelle allo zip\ndef zip_folder(zipf, folder_path, base_folder=\"\"):\n    for root, _, files in os.walk(folder_path):\n        for file in files:\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, base_folder)\n            zipf.write(file_path, arcname)\n\n# Creazione dello zip\nwith zipfile.ZipFile(zip_file_name, 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n    for item in items_to_zip:\n        if os.path.exists(item):  # Verifica che il file o la cartella esista\n            if os.path.isdir(item):  # Se Ã¨ una cartella, aggiungi tutto il contenuto\n                zip_folder(zipf, item, out_dataset_pth)\n            else:  # Se Ã¨ un file, aggiungilo direttamente\n                zipf.write(item)\n        else:\n            print(f\"Elemento non trovato: {item}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:59:05.566630Z","iopub.execute_input":"2025-01-03T00:59:05.567125Z","iopub.status.idle":"2025-01-03T01:00:29.840972Z","shell.execute_reply.started":"2025-01-03T00:59:05.567085Z","shell.execute_reply":"2025-01-03T01:00:29.839486Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Check Yaml","metadata":{}},{"cell_type":"code","source":"def analyze_yolo_dataset(yaml_path):\n    # Carica il file YAML\n    with open(yaml_path, 'r') as f:\n        data = yaml.safe_load(f)\n\n    # Estraggo le informazioni dal file YAML\n    base_path = data['path']\n    sets = ['train', 'val', 'test']\n    stats = {}\n    \n    total_images = 0\n    total_bboxes = Counter()\n    class_names = data['names']\n\n    for dataset_set in sets:\n        images_path = os.path.join(base_path, dataset_set)\n        labels_path = os.path.join(base_path, dataset_set, 'labels')\n\n        # Controlla se le directory esistono\n        if not os.path.exists(images_path) or not os.path.exists(labels_path):\n            print(f\"Directory per il set '{dataset_set}' non trovata.\")\n            continue\n\n        # Conta immagini\n        image_files = [f for f in os.listdir(images_path) if f.endswith(('.jpg'))]\n        num_images = len(image_files)\n        total_images += num_images\n        \n        stats[dataset_set] = {\"images\": num_images, \"bbox\": Counter()}\n\n        # Conta bounding box con tqdm\n        print(f\"Analizzando {dataset_set}...\")\n        for label_file in tqdm(os.listdir(labels_path), desc=f\"Contando bbox in {dataset_set}\", unit=\"file\"):\n            label_path = os.path.join(labels_path, label_file)\n            with open(label_path, 'r') as f:\n                lines = f.readlines()\n                for line in lines:\n                    class_id = line.split()[0]  # La classe Ã¨ il primo elemento della riga\n                    stats[dataset_set][\"bbox\"][class_id] += 1\n                    total_bboxes[class_id] += 1\n\n    return stats, total_images, total_bboxes, class_names\n\n# Funzione per mostrare i risultati con le percentuali calcolate per set\ndef print_stats(stats, total_images, total_bboxes, class_names):\n    print(\"\\n--- ANALISI COMPLESSIVA ---\")\n    print(f\"Totale immagini: {total_images}\")\n    print(f\"Distribuzione complessiva delle categorie:\")\n    \n    # Ordina le classi in base al numero di bbox, dal piÃ¹ grande al piÃ¹ piccolo\n    sorted_bboxes = sorted(total_bboxes.items(), key=lambda x: x[1], reverse=True)\n    \n    for class_id, count in sorted_bboxes:\n        percentage = (count / sum(total_bboxes.values())) * 100\n        print(f\"  Classe {class_names[int(class_id)]} ({class_id}): {count} bbox ({percentage:.2f}%)\")\n    \n    print(\"\\n--- ANALISI PER SET ---\")\n    \n    total_bboxes_all_sets = 0  # Per calcolare il totale complessivo dei bbox\n    for dataset_set, data in stats.items():\n        images_percentage = (data['images'] / total_images) * 100 if total_images > 0 else 0\n        print(f\"\\n--- {dataset_set.upper()} ---\")\n        print(f\"Numero di immagini: {data['images']} ({images_percentage:.2f}%)\")\n        print(\"Distribuzione categorie:\")\n        \n        # Calcola il totale dei bbox per ogni set\n        total_bboxes_in_set = sum(data['bbox'].values())\n        total_bboxes_all_sets += total_bboxes_in_set  # Aggiungi al totale complessivo\n        \n        # Ordina le classi per ogni set in base al numero di bbox\n        sorted_set_bboxes = sorted(data['bbox'].items(), key=lambda x: x[1], reverse=True)\n        \n        for class_id, count in sorted_set_bboxes:\n            percentage = (count / total_bboxes_in_set) * 100 if total_bboxes_in_set > 0 else 0\n            print(f\"  Classe {class_names[int(class_id)]} ({class_id}): {count} bbox ({percentage:.2f}%)\")\n        \n        print(\"Totale bounding box:\", total_bboxes_in_set, f\"({(total_bboxes_in_set / sum(total_bboxes.values())) * 100:.2f}%)\")\n\n    # Aggiungi la percentuale per il totale complessivo dei bounding box\n    print(\"\\n--- TOTALE COMPLESSIVO ---\")\n    print(f\"Totale bounding box: {total_bboxes_all_sets}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Esegui analisi\nstats, total_images, total_bboxes, class_names = analyze_yolo_dataset(dataset_yaml)\nprint_stats(stats, total_images, total_bboxes, class_names)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# YoloV11","metadata":{}},{"cell_type":"code","source":"# Pretrained Model\nmodel = YOLO('yolo11n.pt') \n\n# Configurazione del training\nresults = model.train(\n    data=dataset_yaml,     # Path al file YAML del dataset\n    epochs=50,              # Numero di epoche\n    batch=64,              # Dimensione del batch\n    imgsz=320,             # Dimensione delle immagini (320x320)\n    lr0=0.001,             # Learning rate iniziale\n    save=True,             # Salva i pesi migliori\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T02:12:14.587009Z","iopub.execute_input":"2025-01-03T02:12:14.587358Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 64.6MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Ultralytics 8.3.57 ðŸš€ Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/input/yolodataset-xview/dataset.yaml, epochs=50, time=None, patience=100, batch=64, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 16.4MB/s]\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"results = model.val()  # evaluate model performance on the validation set","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}