{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":10182328,"datasetId":6242793,"databundleVersionId":10471001}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library import","metadata":{}},{"cell_type":"code","source":"import os\nimport subprocess\nimport time\n\nimport yaml\nfrom sklearn.model_selection import GroupKFold\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nfrom tqdm import tqdm\nimport torch.nn as nn\n\nfrom pathlib import Path\nimport json\nfrom collections import defaultdict, Counter\nimport random\nimport random\nimport shutil\nfrom tqdm import tqdm\nimport zipfile\nfrom collections import Counter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T02:11:54.521717Z","iopub.execute_input":"2025-01-03T02:11:54.522067Z","iopub.status.idle":"2025-01-03T02:11:58.570906Z","shell.execute_reply.started":"2025-01-03T02:11:54.522023Z","shell.execute_reply":"2025-01-03T02:11:58.570196Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"%pip install ultralytics\nimport ultralytics\nultralytics.checks()\nfrom ultralytics import YOLO","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T02:11:58.572096Z","iopub.execute_input":"2025-01-03T02:11:58.572446Z","iopub.status.idle":"2025-01-03T02:12:09.446305Z","shell.execute_reply.started":"2025-01-03T02:11:58.572419Z","shell.execute_reply":"2025-01-03T02:12:09.445560Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.57 ðŸš€ Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\nSetup complete âœ… (4 CPUs, 31.4 GB RAM, 6037.6/8062.4 GB disk)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Path","metadata":{}},{"cell_type":"code","source":"COCO_JSON_NM = 'COCO_annotations_new.json'\nOUT_COCO_JSON_NM = 'mod_COCO_annotations.json'\nOUT_IMAGE_FLDR_NM = 'images'\nTRAIN_NM = 'train'\nVAL_NM = 'val'\nTEST_NM = 'test'\nLABEL_NM = 'labels'\nYAML = 'dataset.yaml'\nRANDOM_SEED = 2023\n\nin_dataset_pth = Path('/kaggle/input/our-xview-dataset')\nyolo_dataset_pth = Path('/kaggle/input/yolodataset-xview')\nout_dataset_pth = Path('/kaggle/working/')\nimg_fldr = Path(f'/kaggle/input/our-xview-dataset/{OUT_IMAGE_FLDR_NM}')\n\ncoco_json_pth = in_dataset_pth / COCO_JSON_NM\nnew_coco_json_pth = out_dataset_pth / OUT_COCO_JSON_NM\n\ntrain_img = yolo_dataset_pth / TRAIN_NM / OUT_IMAGE_FLDR_NM\nval_img = yolo_dataset_pth / VAL_NM / OUT_IMAGE_FLDR_NM\ntest_img = yolo_dataset_pth / TEST_NM / OUT_IMAGE_FLDR_NM\ntrain_txt = yolo_dataset_pth / TRAIN_NM / LABEL_NM\nval_txt = yolo_dataset_pth / VAL_NM / LABEL_NM \ntest_txt = yolo_dataset_pth / TEST_NM / LABEL_NM  \ndataset_yaml = yolo_dataset_pth / YAML","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T02:12:09.447832Z","iopub.execute_input":"2025-01-03T02:12:09.448314Z","iopub.status.idle":"2025-01-03T02:12:09.454726Z","shell.execute_reply.started":"2025-01-03T02:12:09.448282Z","shell.execute_reply":"2025-01-03T02:12:09.453480Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Pulizia dell'output per cartelle specifiche\ndef clean_output(output_dir):\n    if output_dir.exists() and output_dir.is_dir():\n        for item in output_dir.iterdir():\n            if item.is_dir():\n                shutil.rmtree(item)  # Rimuove la sotto-cartella\n            else:\n                item.unlink()  # Rimuove il file\n        print(f\"Cartella {output_dir} pulita.\")\n    else:\n        print(f\"Cartella {output_dir} non trovata. Nessuna azione necessaria.\")\n\n# Pulisce la cartella di output prima di avviare il processo\nclean_output(out_dataset_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T02:12:09.455817Z","iopub.execute_input":"2025-01-03T02:12:09.456073Z","iopub.status.idle":"2025-01-03T02:12:09.466900Z","shell.execute_reply.started":"2025-01-03T02:12:09.456048Z","shell.execute_reply":"2025-01-03T02:12:09.466030Z"}},"outputs":[{"name":"stdout","text":"Cartella /kaggle/working pulita.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Utility","metadata":{}},{"cell_type":"code","source":"def load_json(file_path):\n    \"\"\"\n    Carica un file JSON dal percorso specificato.\n\n    :param file_path: Percorso al file JSON da caricare.\n    :return: Dati contenuti nel file JSON (come dizionario o lista).\n    \"\"\"\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T02:12:09.477217Z","iopub.execute_input":"2025-01-03T02:12:09.477457Z","iopub.status.idle":"2025-01-03T02:12:09.486040Z","shell.execute_reply.started":"2025-01-03T02:12:09.477433Z","shell.execute_reply":"2025-01-03T02:12:09.485359Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# COCO Preprocessing","metadata":{}},{"cell_type":"code","source":"def process_custom_coco_json(input_path, output_path):\n    \"\"\"\n    Funzione per processare un JSON COCO in formato personalizzato.\n    \"\"\"\n    # Leggi il JSON dal file di input\n    data = load_json(input_path)\n\n    # Ottieni e correggi il formato delle categorie\n    raw_categories = data.get('categories', [])\n    categories = []\n \n    for category in tqdm(raw_categories, desc=\"Processing Categories\"):\n        for id_str, name in category.items():\n            try:\n                categories.append({\"id\": int(id_str), \"name\": name})\n            except ValueError:\n                print(f\"Errore nel parsing della categoria: {category}\")\n \n    # Preprocessa le annotazioni in un dizionario per immagini\n    image_annotations_dict = {}\n    for annotation in tqdm(data.get('annotations', []), desc=\"Building Image Annotations Dictionary\"):\n        image_id = annotation['image_id']\n        if image_id not in image_annotations_dict:\n            image_annotations_dict[image_id] = []\n        image_annotations_dict[image_id].append(annotation)\n \n    # Elenco di annotazioni da mantenere (solo quelle valide)\n    valid_annotations = []\n    annotations_to_remove = set()\n \n    # Controllo dei bounding box\n    for annotation in tqdm(data.get('annotations', []), desc=\"Processing Annotations\"):\n        \n        # Converte il formato del bbox\n        if isinstance(annotation['bbox'], str):\n            annotation['bbox'] = json.loads(annotation['bbox'])\n        \n        x, y, width, height = annotation['bbox']\n        xmin, xmax = x, x + width\n        ymin, ymax = y, y + height\n        \n        # Verifica che xmin < xmax e ymin < ymax, e che la larghezza e altezza siano sufficienti\n        if xmin >= xmax or ymin >= ymax or width <= 10 or height <= 10:\n            annotations_to_remove.add(annotation['id'])\n        else:\n            annotation['bbox'] = [xmin, ymin, xmax, ymax]\n            valid_annotations.append(annotation)\n \n    # Rimuovi le annotazioni non valide\n    data['annotations'] = valid_annotations\n \n    # Ordina le categorie per ID\n    categories = sorted(categories, key=lambda x: x['id'])\n    \n    # Aggiorna le categorie nel JSON\n    data['categories'] = categories\n\n \n    # Scrivi il JSON modificato nel file di output\n    with open(output_path, 'w') as f:\n        json.dump(data, f, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:54:31.052160Z","iopub.execute_input":"2025-01-02T23:54:31.052533Z","iopub.status.idle":"2025-01-02T23:54:31.066678Z","shell.execute_reply.started":"2025-01-02T23:54:31.052498Z","shell.execute_reply":"2025-01-02T23:54:31.065462Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"process_custom_coco_json(coco_json_pth, new_coco_json_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:54:31.067997Z","iopub.execute_input":"2025-01-02T23:54:31.068621Z","iopub.status.idle":"2025-01-02T23:54:46.296641Z","shell.execute_reply.started":"2025-01-02T23:54:31.068409Z","shell.execute_reply":"2025-01-02T23:54:46.295546Z"}},"outputs":[{"name":"stderr","text":"Processing Categories: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:00<00:00, 61929.32it/s]\nBuilding Image Annotations Dictionary: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 669983/669983 [00:00<00:00, 1909198.08it/s]\nProcessing Annotations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 669983/669983 [00:04<00:00, 167462.72it/s]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### Category Check","metadata":{}},{"cell_type":"code","source":"def count_bounding_boxes(json_path):\n    \"\"\"\n    Conta il numero di bounding box per ogni categoria in un file COCO JSON.\n\n    Args:\n        json_path (str): Percorso del file JSON.\n\n    Returns:\n        list: Elenco di tuple con ID categoria, nome categoria e numero di bounding box.\n    \"\"\"\n    # Carica il file JSON\n    coco_data = load_json(json_path)\n\n    # Estrarre i dati principali\n    annotations = coco_data.get(\"annotations\", [])\n    categories = coco_data.get(\"categories\", [])\n\n    # Mappare id di categoria ai nomi delle categorie\n    category_id_to_name = {category[\"id\"]: category[\"name\"] for category in categories}\n\n    # Contare i bounding box per categoria\n    bbox_counts = defaultdict(int)\n    for annotation in annotations:\n        category_id = annotation[\"category_id\"]\n        bbox_counts[category_id] += 1\n\n    # Creare un elenco dei risultati\n    results = [\n        (cat_id, category_id_to_name.get(cat_id, \"Unknown\"), count)\n        for cat_id, count in bbox_counts.items()\n    ]\n    \n    # Ordinare i risultati in ordine decrescente per numero di bounding box\n    results.sort(key=lambda x: x[2], reverse=True)\n    \n    # Stampare i risultati\n    for cat_id, category_name, count in results:\n        print(f\"Categoria ID {cat_id} ('{category_name}'): {count} bounding box\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:54:46.297869Z","iopub.execute_input":"2025-01-02T23:54:46.298311Z","iopub.status.idle":"2025-01-02T23:54:46.306707Z","shell.execute_reply.started":"2025-01-02T23:54:46.298266Z","shell.execute_reply":"2025-01-02T23:54:46.305538Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"count_bounding_boxes(new_coco_json_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:54:46.310522Z","iopub.execute_input":"2025-01-02T23:54:46.311001Z","iopub.status.idle":"2025-01-02T23:54:49.180033Z","shell.execute_reply.started":"2025-01-02T23:54:46.310953Z","shell.execute_reply":"2025-01-02T23:54:49.179001Z"}},"outputs":[{"name":"stdout","text":"Categoria ID 6 ('Building'): 343313 bounding box\nCategoria ID 1 ('Passenger Vehicle'): 93827 bounding box\nCategoria ID 2 ('Truck'): 24582 bounding box\nCategoria ID 4 ('Maritime Vessel'): 5161 bounding box\nCategoria ID 5 ('Engineering Vehicle'): 4728 bounding box\nCategoria ID 9 ('Shipping Container'): 4558 bounding box\nCategoria ID 3 ('Railway Vehicle'): 3691 bounding box\nCategoria ID 8 ('Storage Tank'): 1743 bounding box\nCategoria ID 0 ('Aircraft'): 1561 bounding box\nCategoria ID 10 ('Pylon'): 415 bounding box\nCategoria ID 7 ('Helipad'): 136 bounding box\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# JSON to YOLO","metadata":{}},{"cell_type":"code","source":"def convert_json_to_yolo(json_path, images_dir, output_dir, input_dir, train_dir_out, val_dir_out, test_dir_out, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n    # Carica il file JSON\n    with open(json_path) as f:\n        data = json.load(f)\n\n    # Mappa le classi\n    class_mapping = {category['id']: category['name'] for category in data['categories']}\n    nc = len(class_mapping)  # Numero di classi\n\n    # Crea le cartelle per il dataset\n    train_images_dir = os.path.join(output_dir, 'train', 'images')\n    val_images_dir = os.path.join(output_dir, 'val', 'images')\n    test_images_dir = os.path.join(output_dir, 'test', 'images')\n\n    train_labels_dir = os.path.join(output_dir, 'train', 'labels')\n    val_labels_dir = os.path.join(output_dir, 'val', 'labels')\n    test_labels_dir = os.path.join(output_dir, 'test', 'labels')\n    \n    for dir_path in [train_images_dir, val_images_dir, test_images_dir, train_labels_dir, val_labels_dir, test_labels_dir]:\n        os.makedirs(dir_path, exist_ok=True)\n\n    # Dividi le immagini in training, validation, and test\n    images = data['images']\n    random.shuffle(images)\n    total_images = len(images)\n    \n    train_split = int(train_ratio * total_images)\n    val_split = int((train_ratio + val_ratio) * total_images)\n\n    train_images = images[:train_split]\n    val_images = images[train_split:val_split]\n    test_images = images[val_split:]\n\n    # Funzione per copiare le immagini in una cartella specifica\n    def copy_images(image_list, target_dir):\n        for image in tqdm(image_list, desc=f\"Copying images to {target_dir}\", unit=\"image\"):\n            src_path = os.path.join(images_dir, image['file_name'])\n            dst_path = os.path.join(target_dir, image['file_name'])\n            shutil.copy(src_path, dst_path)\n\n    # Copia le immagini nelle rispettive cartelle\n    copy_images(train_images, train_images_dir)\n    copy_images(val_images, val_images_dir)\n    copy_images(test_images, test_images_dir)\n\n    # Converte le annotazioni in formato YOLO e salva nei file di testo\n    def convert_annotations(image, annotations, target_dir):\n        image_id = image['id']\n        image_width = image['width']\n        image_height = image['height']\n        image_name = image['file_name']\n\n        label_file_path = os.path.join(target_dir, f\"{image_name.replace('.jpg', '.txt')}\")\n        label_dir = os.path.dirname(label_file_path)\n\n        # Crea la cartella se non esiste\n        os.makedirs(label_dir, exist_ok=True)\n\n        with open(label_file_path, 'w') as label_file:\n            for annotation in annotations:\n                if annotation['image_id'] == image_id:\n                    category_id = annotation['category_id']\n                    xmin, ymin, xmax, ymax = annotation['bbox']\n\n                    # Normalizza le coordinate\n                    x_center = (xmin + xmax) / 2 / image_width\n                    y_center = (ymin + ymax) / 2 / image_height\n                    width = (xmax - xmin) / image_width\n                    height = (ymax - ymin) / image_height\n\n                    # Scrivi nel file di annotazione\n                    label_file.write(f\"{category_id} {x_center} {y_center} {width} {height}\\n\")\n\n    # Converte le annotazioni per ogni immagine e le salva nelle cartelle appropriate\n    def process_images(image_list, target_dir, label_target_dir):\n        for image in tqdm(image_list, desc=f\"Converting annotations\", unit=\"image\"):\n            annotations = [annotation for annotation in data['annotations'] if annotation['image_id'] == image['id']]\n            convert_annotations(image, annotations, label_target_dir)\n\n    # Processa le immagini per training, validation e test\n    process_images(train_images, 'train', train_labels_dir)\n    process_images(val_images, 'val', val_labels_dir)\n    process_images(test_images, 'test', test_labels_dir)\n        \n    # Crea il file YAML per YOLO\n    yaml_content = f\"\"\"path: {input_dir}\ntrain: {train_dir_out}  # train images\nval: {val_dir_out}  # val images\ntest: {test_dir_out}  # test images\n\n# Classes\nnc: {nc}  # number of classes\nnames:\n\"\"\"\n    # Aggiungi le classi al file YAML\n    for idx, class_name in class_mapping.items():\n        yaml_content += f\"  {int(idx)}: {class_name}\\n\"  # Assicurati che l'indice sia numerico senza virgolette\n\n    # Scrivi il file YAML\n    with open(os.path.join(output_dir, 'dataset.yaml'), 'w') as yaml_file:\n        yaml_file.write(yaml_content.strip())\n\n    print(\"Conversione e split completati.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:54:49.182025Z","iopub.execute_input":"2025-01-02T23:54:49.182403Z","iopub.status.idle":"2025-01-02T23:54:49.198670Z","shell.execute_reply.started":"2025-01-02T23:54:49.182334Z","shell.execute_reply":"2025-01-02T23:54:49.197604Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"convert_json_to_yolo(\n    json_path=new_coco_json_pth,\n    images_dir=img_fldr,\n    output_dir=out_dataset_pth,\n    input_dir=yolo_dataset_pth,\n    train_dir_out=train_img,\n    val_dir_out=val_img,\n    test_dir_out=test_img,\n    train_ratio=0.8,\n    val_ratio=0.1,\n    test_ratio=0.1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:54:49.200221Z","iopub.execute_input":"2025-01-02T23:54:49.200703Z","iopub.status.idle":"2025-01-03T00:58:47.820800Z","shell.execute_reply.started":"2025-01-02T23:54:49.200654Z","shell.execute_reply":"2025-01-03T00:58:47.818741Z"}},"outputs":[{"name":"stderr","text":"Copying images to /kaggle/working/train/images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36712/36712 [05:46<00:00, 106.04image/s]\nCopying images to /kaggle/working/val/images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4589/4589 [00:43<00:00, 104.65image/s]\nCopying images to /kaggle/working/test/images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4590/4590 [00:43<00:00, 104.87image/s]\nConverting annotations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36712/36712 [45:12<00:00, 13.54image/s]\nConverting annotations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4589/4589 [05:34<00:00, 13.71image/s]\nConverting annotations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4590/4590 [05:54<00:00, 12.93image/s]\n","output_type":"stream"},{"name":"stdout","text":"Conversione e split completati.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Nome del file zip da creare\nzip_file_name = \"YOLO_dataset.zip\"\n\n# Elenco di file e cartelle da includere nello zip\nitems_to_zip = [\n    \"test\",\n    \"train\",\n    \"val\",\n    \"dataset.yaml\",\n]\n\n# Funzione per aggiungere file e cartelle allo zip\ndef zip_folder(zipf, folder_path, base_folder=\"\"):\n    for root, _, files in os.walk(folder_path):\n        for file in files:\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, base_folder)\n            zipf.write(file_path, arcname)\n\n# Creazione dello zip\nwith zipfile.ZipFile(zip_file_name, 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n    for item in items_to_zip:\n        if os.path.exists(item):  # Verifica che il file o la cartella esista\n            if os.path.isdir(item):  # Se Ã¨ una cartella, aggiungi tutto il contenuto\n                zip_folder(zipf, item, out_dataset_pth)\n            else:  # Se Ã¨ un file, aggiungilo direttamente\n                zipf.write(item)\n        else:\n            print(f\"Elemento non trovato: {item}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:59:05.566630Z","iopub.execute_input":"2025-01-03T00:59:05.567125Z","iopub.status.idle":"2025-01-03T01:00:29.840972Z","shell.execute_reply.started":"2025-01-03T00:59:05.567085Z","shell.execute_reply":"2025-01-03T01:00:29.839486Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Check Yaml","metadata":{}},{"cell_type":"code","source":"def analyze_yolo_dataset(yaml_path):\n    # Carica il file YAML\n    with open(yaml_path, 'r') as f:\n        data = yaml.safe_load(f)\n\n    # Estraggo le informazioni dal file YAML\n    base_path = data['path']\n    sets = ['train', 'val', 'test']\n    stats = {}\n    \n    total_images = 0\n    total_bboxes = Counter()\n    class_names = data['names']\n\n    for dataset_set in sets:\n        images_path = os.path.join(base_path, dataset_set)\n        labels_path = os.path.join(base_path, dataset_set, 'labels')\n\n        # Controlla se le directory esistono\n        if not os.path.exists(images_path) or not os.path.exists(labels_path):\n            print(f\"Directory per il set '{dataset_set}' non trovata.\")\n            continue\n\n        # Conta immagini\n        image_files = [f for f in os.listdir(images_path) if f.endswith(('.jpg'))]\n        num_images = len(image_files)\n        total_images += num_images\n        \n        stats[dataset_set] = {\"images\": num_images, \"bbox\": Counter()}\n\n        # Conta bounding box con tqdm\n        print(f\"Analizzando {dataset_set}...\")\n        for label_file in tqdm(os.listdir(labels_path), desc=f\"Contando bbox in {dataset_set}\", unit=\"file\"):\n            label_path = os.path.join(labels_path, label_file)\n            with open(label_path, 'r') as f:\n                lines = f.readlines()\n                for line in lines:\n                    class_id = line.split()[0]  # La classe Ã¨ il primo elemento della riga\n                    stats[dataset_set][\"bbox\"][class_id] += 1\n                    total_bboxes[class_id] += 1\n\n    return stats, total_images, total_bboxes, class_names\n\n# Funzione per mostrare i risultati con le percentuali calcolate per set\ndef print_stats(stats, total_images, total_bboxes, class_names):\n    print(\"\\n--- ANALISI COMPLESSIVA ---\")\n    print(f\"Totale immagini: {total_images}\")\n    print(f\"Distribuzione complessiva delle categorie:\")\n    \n    # Ordina le classi in base al numero di bbox, dal piÃ¹ grande al piÃ¹ piccolo\n    sorted_bboxes = sorted(total_bboxes.items(), key=lambda x: x[1], reverse=True)\n    \n    for class_id, count in sorted_bboxes:\n        percentage = (count / sum(total_bboxes.values())) * 100\n        print(f\"  Classe {class_names[int(class_id)]} ({class_id}): {count} bbox ({percentage:.2f}%)\")\n    \n    print(\"\\n--- ANALISI PER SET ---\")\n    \n    total_bboxes_all_sets = 0  # Per calcolare il totale complessivo dei bbox\n    for dataset_set, data in stats.items():\n        images_percentage = (data['images'] / total_images) * 100 if total_images > 0 else 0\n        print(f\"\\n--- {dataset_set.upper()} ---\")\n        print(f\"Numero di immagini: {data['images']} ({images_percentage:.2f}%)\")\n        print(\"Distribuzione categorie:\")\n        \n        # Calcola il totale dei bbox per ogni set\n        total_bboxes_in_set = sum(data['bbox'].values())\n        total_bboxes_all_sets += total_bboxes_in_set  # Aggiungi al totale complessivo\n        \n        # Ordina le classi per ogni set in base al numero di bbox\n        sorted_set_bboxes = sorted(data['bbox'].items(), key=lambda x: x[1], reverse=True)\n        \n        for class_id, count in sorted_set_bboxes:\n            percentage = (count / total_bboxes_in_set) * 100 if total_bboxes_in_set > 0 else 0\n            print(f\"  Classe {class_names[int(class_id)]} ({class_id}): {count} bbox ({percentage:.2f}%)\")\n        \n        print(\"Totale bounding box:\", total_bboxes_in_set, f\"({(total_bboxes_in_set / sum(total_bboxes.values())) * 100:.2f}%)\")\n\n    # Aggiungi la percentuale per il totale complessivo dei bounding box\n    print(\"\\n--- TOTALE COMPLESSIVO ---\")\n    print(f\"Totale bounding box: {total_bboxes_all_sets}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Esegui analisi\nstats, total_images, total_bboxes, class_names = analyze_yolo_dataset(dataset_yaml)\nprint_stats(stats, total_images, total_bboxes, class_names)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# YoloV11","metadata":{}},{"cell_type":"code","source":"# Pretrained Model\nmodel = YOLO('yolo11n.pt') \n\n# Configurazione del training\nresults = model.train(\n    data=dataset_yaml,     # Path al file YAML del dataset\n    epochs=150,            # Numero di epoche\n    batch=64,              # Dimensione del batch\n    imgsz=320,             # Dimensione delle immagini (320x320)\n    lr0=0.001,             # Learning rate iniziale\n    save=True,             # Salva i pesi migliori\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T02:12:14.587009Z","iopub.execute_input":"2025-01-03T02:12:14.587358Z","iopub.status.idle":"2025-01-03T02:56:29.565956Z","shell.execute_reply.started":"2025-01-03T02:12:14.587328Z","shell.execute_reply":"2025-01-03T02:56:29.564493Z"}},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 64.6MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Ultralytics 8.3.57 ðŸš€ Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/input/yolodataset-xview/dataset.yaml, epochs=50, time=None, patience=100, batch=64, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 16.4MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=11\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    432817  ultralytics.nn.modules.head.Detect           [11, [64, 128, 256]]          \nYOLO11n summary: 319 layers, 2,591,985 parameters, 2,591,969 gradients, 6.5 GFLOPs\n\nTransferred 448/499 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/yolodataset-xview/train/labels... 36712 images, 11847 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36712/36712 [01:34<00:00, 387.05it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_1449_960_1280.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_1832_0_0.jpg: 69 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_1832_0_1600.jpg: 36 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_1832_0_1920.jpg: 44 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_1832_0_2240.jpg: 43 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_1832_0_2560.jpg: 23 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_1832_0_320.jpg: 66 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_1832_0_640.jpg: 50 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_1896_0_0.jpg: 59 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_1896_0_1920.jpg: 38 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_1896_0_2240.jpg: 68 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_1896_0_640.jpg: 87 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_1896_0_960.jpg: 33 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_18_320_0.jpg: 69 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_18_320_1280.jpg: 48 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_18_320_2240.jpg: 43 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_18_320_2560.jpg: 23 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_18_320_640.jpg: 50 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_18_320_960.jpg: 33 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_18_960_0.jpg: 59 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_18_960_1600.jpg: 21 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_18_960_1920.jpg: 38 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_18_960_2240.jpg: 68 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_18_960_2560.jpg: 75 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_18_960_320.jpg: 96 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_18_960_640.jpg: 87 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_18_960_960.jpg: 33 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_2032_0_1280.jpg: 22 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_2032_0_1600.jpg: 24 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_2032_0_1920.jpg: 25 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_2032_0_2240.jpg: 33 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_2032_0_2560.jpg: 34 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_2032_0_320.jpg: 7 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_2064_0_1280.jpg: 12 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_2064_0_1600.jpg: 11 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_2064_0_1920.jpg: 12 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_2064_0_2240.jpg: 18 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_20_320_1280.jpg: 22 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_20_320_1920.jpg: 25 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_20_320_2560.jpg: 34 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_20_320_320.jpg: 7 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_20_320_640.jpg: 26 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_20_320_960.jpg: 19 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_20_640_1280.jpg: 12 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_20_640_1920.jpg: 12 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_20_640_2240.jpg: 18 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_20_640_2560.jpg: 27 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_2230_320_0.jpg: 5 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_532_0_2240.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_532_0_2560.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_532_0_320.jpg: 14 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_596_0_1280.jpg: 10 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_596_0_1920.jpg: 6 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_5_320_320.jpg: 14 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_5_960_1280.jpg: 10 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/train/images/img_5_960_1920.jpg: 6 duplicate labels removed\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ Cache directory /kaggle/input/yolodataset-xview/train is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.24 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/yolodataset-xview/val/labels... 4589 images, 1496 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4589/4589 [00:11<00:00, 415.19it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/val/images/img_1832_0_960.jpg: 33 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/val/images/img_1896_0_1600.jpg: 21 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/val/images/img_1896_0_2560.jpg: 75 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/val/images/img_18_320_1600.jpg: 36 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/val/images/img_2032_0_640.jpg: 26 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/val/images/img_2032_0_960.jpg: 19 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/val/images/img_20_640_1600.jpg: 11 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/val/images/img_223_0_3200.jpg: 5 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/val/images/img_5_320_2240.jpg: 2 duplicate labels removed\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ Cache directory /kaggle/input/yolodataset-xview/val is not writeable, cache not saved.\nPlotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 320 train, 320 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/50      7.74G      2.045      2.502       1.47        576        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [02:24<00:00,  3.97it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:21<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075       0.69      0.119     0.0874     0.0361\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/50      6.39G      1.952      1.689       1.38        462        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [02:16<00:00,  4.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:20<00:00,  1.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.424      0.167      0.108     0.0456\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/50      5.19G      1.992      1.686      1.392        590        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [02:15<00:00,  4.24it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:21<00:00,  1.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.336      0.234      0.109     0.0448\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/50      7.77G      1.996      1.665      1.396        539        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [02:15<00:00,  4.25it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:20<00:00,  1.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.418      0.208      0.163     0.0663\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       5/50      4.84G      1.957        1.6      1.378        533        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [02:35<00:00,  3.70it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:19<00:00,  1.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.351       0.24      0.184     0.0818\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       6/50      5.43G      1.927      1.544       1.36        426        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [02:29<00:00,  3.84it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:19<00:00,  1.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.366      0.241        0.2     0.0879\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       7/50      5.42G      1.911      1.523      1.358        771        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [02:18<00:00,  4.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:19<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.482      0.252      0.207     0.0915\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       8/50      6.57G      1.891      1.496      1.345        453        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [02:17<00:00,  4.17it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:19<00:00,  1.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.565      0.292      0.261      0.112\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       9/50      6.05G      1.883      1.472      1.341        578        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [02:19<00:00,  4.11it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:19<00:00,  1.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.511      0.299      0.267      0.118\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      10/50      5.93G      1.874      1.456      1.338        382        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [02:15<00:00,  4.25it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:19<00:00,  1.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075       0.55      0.284      0.283      0.133\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      11/50      6.13G       1.87      1.449      1.334        713        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [02:17<00:00,  4.18it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:19<00:00,  1.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.536      0.299      0.286      0.129\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      12/50      7.73G      1.858      1.441      1.325        617        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [02:17<00:00,  4.17it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:19<00:00,  1.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075       0.56      0.306      0.307      0.141\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      13/50      6.98G       1.85      1.429      1.323        544        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [02:16<00:00,  4.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:19<00:00,  1.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.442      0.334      0.319      0.147\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      14/50      4.83G       1.85      1.417      1.321        668        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [02:14<00:00,  4.27it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:19<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075       0.49      0.327      0.336      0.156\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      15/50      5.25G      1.839       1.41      1.315        545        320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [02:13<00:00,  4.29it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:19<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.475      0.338      0.338       0.16\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      16/50      7.25G      1.842      1.408      1.317        696        320:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 208/574 [00:48<01:24,  4.31it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolo11n.pt\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Configurazione del training\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_yaml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Path al file YAML del dataset\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Numero di epoche\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Dimensione del batch\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# Dimensione delle immagini (320x320)\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# Learning rate iniziale\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# Salva i pesi migliori\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py:806\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 806\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py:207\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py:362\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    360\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m TQDM(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader), total\u001b[38;5;241m=\u001b[39mnb)\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_train_batch_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;66;03m# Warmup\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/data/build.py:48\u001b[0m, in \u001b[0;36mInfiniteDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a sampler that repeats indefinitely.\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1283\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1283\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1284\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1285\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n","File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"results = model.val(data=dataset_yaml)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T02:57:22.084473Z","iopub.execute_input":"2025-01-03T02:57:22.085130Z","iopub.status.idle":"2025-01-03T02:58:18.163406Z","shell.execute_reply.started":"2025-01-03T02:57:22.085096Z","shell.execute_reply":"2025-01-03T02:58:18.162341Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.57 ðŸš€ Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/yolodataset-xview/val/labels... 4589 images, 1496 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4589/4589 [00:05<00:00, 846.65it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/val/images/img_1832_0_960.jpg: 33 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/val/images/img_1896_0_1600.jpg: 21 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/val/images/img_1896_0_2560.jpg: 75 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/val/images/img_18_320_1600.jpg: 36 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/val/images/img_2032_0_640.jpg: 26 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/val/images/img_2032_0_960.jpg: 19 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/val/images/img_20_640_1600.jpg: 11 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/val/images/img_223_0_3200.jpg: 5 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /kaggle/input/yolodataset-xview/val/images/img_5_320_2240.jpg: 2 duplicate labels removed\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ Cache directory /kaggle/input/yolodataset-xview/val is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 287/287 [00:44<00:00,  6.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.401      0.216       0.17      0.076\n              Aircraft         78        133      0.556      0.564      0.539      0.254\n     Passenger Vehicle       1400       9562      0.391      0.277      0.271     0.0982\n                 Truck        789       2400      0.266     0.0558     0.0644     0.0276\n       Railway Vehicle         47        221      0.188      0.118     0.0644      0.028\n       Maritime Vessel        140        515     0.0933      0.384      0.106     0.0493\n   Engineering Vehicle        218        419      0.127     0.0525     0.0296     0.0122\n              Building       2528      34228      0.436      0.591      0.501      0.236\n               Helipad          7          7          1          0     0.0013   0.000575\n          Storage Tank         62        173      0.297      0.329      0.268      0.119\n    Shipping Container        123        376     0.0523    0.00266     0.0264    0.00972\n                 Pylon         34         41          1          0    0.00146   0.000567\nSpeed: 0.2ms preprocess, 3.9ms inference, 0.0ms loss, 1.7ms postprocess per image\nResults saved to \u001b[1mruns/detect/val2\u001b[0m\n","output_type":"stream"}],"execution_count":9}]}