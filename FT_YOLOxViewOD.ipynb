{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10182328,"sourceType":"datasetVersion","datasetId":6242793},{"sourceId":10359387,"sourceType":"datasetVersion","datasetId":6414860}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library import","metadata":{}},{"cell_type":"code","source":"import os\nimport subprocess\nimport time\n\nimport yaml\nfrom sklearn.model_selection import GroupKFold\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nfrom tqdm import tqdm\nimport torch.nn as nn\n\nfrom pathlib import Path\nimport json\nfrom collections import defaultdict, Counter\nimport random\nimport random\nimport shutil\nfrom tqdm import tqdm\nimport zipfile\nfrom collections import Counter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:29:47.041368Z","iopub.execute_input":"2025-01-04T14:29:47.041680Z","iopub.status.idle":"2025-01-04T14:29:51.230272Z","shell.execute_reply.started":"2025-01-04T14:29:47.041655Z","shell.execute_reply":"2025-01-04T14:29:51.229554Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"%pip install ultralytics\nimport ultralytics\nultralytics.checks()\nfrom ultralytics import YOLO","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:29:56.192207Z","iopub.execute_input":"2025-01-04T14:29:56.193076Z","iopub.status.idle":"2025-01-04T14:30:07.959987Z","shell.execute_reply.started":"2025-01-04T14:29:56.193039Z","shell.execute_reply":"2025-01-04T14:30:07.959253Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.57 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\nSetup complete ✅ (4 CPUs, 31.4 GB RAM, 6037.6/8062.4 GB disk)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Path","metadata":{}},{"cell_type":"code","source":"COCO_JSON_NM = 'COCO_annotations_new.json'\nOUT_COCO_JSON_NM = 'mod_COCO_annotations.json'\nOUT_IMAGE_FLDR_NM = 'images'\nTRAIN_NM = 'train'\nVAL_NM = 'val'\nTEST_NM = 'test'\nLABEL_NM = 'labels'\nYAML = 'dataset.yaml'\nRANDOM_SEED = 2023\n\nin_dataset_pth = Path('/kaggle/input/our-xview-dataset')\nyolo_dataset_pth = Path('/kaggle/input/yolodataset-xview')\nout_dataset_pth = Path('/kaggle/working/')\nimg_fldr = Path(f'/kaggle/input/our-xview-dataset/{OUT_IMAGE_FLDR_NM}')\n\ncoco_json_pth = in_dataset_pth / COCO_JSON_NM\nnew_coco_json_pth = out_dataset_pth / OUT_COCO_JSON_NM\n\ntrain_img = yolo_dataset_pth / TRAIN_NM / OUT_IMAGE_FLDR_NM\nval_img = yolo_dataset_pth / VAL_NM / OUT_IMAGE_FLDR_NM\ntest_img = yolo_dataset_pth / TEST_NM / OUT_IMAGE_FLDR_NM\ntrain_txt = yolo_dataset_pth / TRAIN_NM / LABEL_NM\nval_txt = yolo_dataset_pth / VAL_NM / LABEL_NM \ntest_txt = yolo_dataset_pth / TEST_NM / LABEL_NM  \ndataset_yaml = yolo_dataset_pth / YAML","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:30:15.788701Z","iopub.execute_input":"2025-01-04T14:30:15.789568Z","iopub.status.idle":"2025-01-04T14:30:15.795388Z","shell.execute_reply.started":"2025-01-04T14:30:15.789531Z","shell.execute_reply":"2025-01-04T14:30:15.794152Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Pulizia dell'output per cartelle specifiche\ndef clean_output(output_dir):\n    if output_dir.exists() and output_dir.is_dir():\n        for item in output_dir.iterdir():\n            if item.is_dir():\n                shutil.rmtree(item)  # Rimuove la sotto-cartella\n            else:\n                item.unlink()  # Rimuove il file\n        print(f\"Cartella {output_dir} pulita.\")\n    else:\n        print(f\"Cartella {output_dir} non trovata. Nessuna azione necessaria.\")\n\n# Pulisce la cartella di output prima di avviare il processo\nclean_output(out_dataset_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T08:58:58.800030Z","iopub.execute_input":"2025-01-04T08:58:58.800397Z","iopub.status.idle":"2025-01-04T08:58:58.806683Z","shell.execute_reply.started":"2025-01-04T08:58:58.800366Z","shell.execute_reply":"2025-01-04T08:58:58.805888Z"}},"outputs":[{"name":"stdout","text":"Cartella /kaggle/working pulita.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Utility","metadata":{}},{"cell_type":"code","source":"def load_json(file_path):\n    \"\"\"\n    Carica un file JSON dal percorso specificato.\n\n    :param file_path: Percorso al file JSON da caricare.\n    :return: Dati contenuti nel file JSON (come dizionario o lista).\n    \"\"\"\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T02:12:09.477217Z","iopub.execute_input":"2025-01-03T02:12:09.477457Z","iopub.status.idle":"2025-01-03T02:12:09.486040Z","shell.execute_reply.started":"2025-01-03T02:12:09.477433Z","shell.execute_reply":"2025-01-03T02:12:09.485359Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# COCO Preprocessing","metadata":{}},{"cell_type":"code","source":"def process_custom_coco_json(input_path, output_path):\n    \"\"\"\n    Funzione per processare un JSON COCO in formato personalizzato.\n    \"\"\"\n    # Leggi il JSON dal file di input\n    data = load_json(input_path)\n\n    # Ottieni e correggi il formato delle categorie\n    raw_categories = data.get('categories', [])\n    categories = []\n \n    for category in tqdm(raw_categories, desc=\"Processing Categories\"):\n        for id_str, name in category.items():\n            try:\n                categories.append({\"id\": int(id_str), \"name\": name})\n            except ValueError:\n                print(f\"Errore nel parsing della categoria: {category}\")\n \n    # Preprocessa le annotazioni in un dizionario per immagini\n    image_annotations_dict = {}\n    for annotation in tqdm(data.get('annotations', []), desc=\"Building Image Annotations Dictionary\"):\n        image_id = annotation['image_id']\n        if image_id not in image_annotations_dict:\n            image_annotations_dict[image_id] = []\n        image_annotations_dict[image_id].append(annotation)\n \n    # Elenco di annotazioni da mantenere (solo quelle valide)\n    valid_annotations = []\n    annotations_to_remove = set()\n \n    # Controllo dei bounding box\n    for annotation in tqdm(data.get('annotations', []), desc=\"Processing Annotations\"):\n        \n        # Converte il formato del bbox\n        if isinstance(annotation['bbox'], str):\n            annotation['bbox'] = json.loads(annotation['bbox'])\n        \n        x, y, width, height = annotation['bbox']\n        xmin, xmax = x, x + width\n        ymin, ymax = y, y + height\n        \n        # Verifica che xmin < xmax e ymin < ymax, e che la larghezza e altezza siano sufficienti\n        if xmin >= xmax or ymin >= ymax or width <= 10 or height <= 10:\n            annotations_to_remove.add(annotation['id'])\n        else:\n            annotation['bbox'] = [xmin, ymin, xmax, ymax]\n            valid_annotations.append(annotation)\n \n    # Rimuovi le annotazioni non valide\n    data['annotations'] = valid_annotations\n \n    # Ordina le categorie per ID\n    categories = sorted(categories, key=lambda x: x['id'])\n    \n    # Aggiorna le categorie nel JSON\n    data['categories'] = categories\n\n \n    # Scrivi il JSON modificato nel file di output\n    with open(output_path, 'w') as f:\n        json.dump(data, f, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:54:31.052160Z","iopub.execute_input":"2025-01-02T23:54:31.052533Z","iopub.status.idle":"2025-01-02T23:54:31.066678Z","shell.execute_reply.started":"2025-01-02T23:54:31.052498Z","shell.execute_reply":"2025-01-02T23:54:31.065462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"process_custom_coco_json(coco_json_pth, new_coco_json_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:54:31.067997Z","iopub.execute_input":"2025-01-02T23:54:31.068621Z","iopub.status.idle":"2025-01-02T23:54:46.296641Z","shell.execute_reply.started":"2025-01-02T23:54:31.068409Z","shell.execute_reply":"2025-01-02T23:54:46.295546Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Category Check","metadata":{}},{"cell_type":"code","source":"def count_bounding_boxes(json_path):\n    \"\"\"\n    Conta il numero di bounding box per ogni categoria in un file COCO JSON.\n\n    Args:\n        json_path (str): Percorso del file JSON.\n\n    Returns:\n        list: Elenco di tuple con ID categoria, nome categoria e numero di bounding box.\n    \"\"\"\n    # Carica il file JSON\n    coco_data = load_json(json_path)\n\n    # Estrarre i dati principali\n    annotations = coco_data.get(\"annotations\", [])\n    categories = coco_data.get(\"categories\", [])\n\n    # Mappare id di categoria ai nomi delle categorie\n    category_id_to_name = {category[\"id\"]: category[\"name\"] for category in categories}\n\n    # Contare i bounding box per categoria\n    bbox_counts = defaultdict(int)\n    for annotation in annotations:\n        category_id = annotation[\"category_id\"]\n        bbox_counts[category_id] += 1\n\n    # Creare un elenco dei risultati\n    results = [\n        (cat_id, category_id_to_name.get(cat_id, \"Unknown\"), count)\n        for cat_id, count in bbox_counts.items()\n    ]\n    \n    # Ordinare i risultati in ordine decrescente per numero di bounding box\n    results.sort(key=lambda x: x[2], reverse=True)\n    \n    # Stampare i risultati\n    for cat_id, category_name, count in results:\n        print(f\"Categoria ID {cat_id} ('{category_name}'): {count} bounding box\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:54:46.297869Z","iopub.execute_input":"2025-01-02T23:54:46.298311Z","iopub.status.idle":"2025-01-02T23:54:46.306707Z","shell.execute_reply.started":"2025-01-02T23:54:46.298266Z","shell.execute_reply":"2025-01-02T23:54:46.305538Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"count_bounding_boxes(new_coco_json_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:54:46.310522Z","iopub.execute_input":"2025-01-02T23:54:46.311001Z","iopub.status.idle":"2025-01-02T23:54:49.180033Z","shell.execute_reply.started":"2025-01-02T23:54:46.310953Z","shell.execute_reply":"2025-01-02T23:54:49.179001Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# JSON to YOLO","metadata":{}},{"cell_type":"code","source":"def convert_json_to_yolo(json_path, images_dir, output_dir, input_dir, train_dir_out, val_dir_out, test_dir_out, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n    # Carica il file JSON\n    with open(json_path) as f:\n        data = json.load(f)\n\n    # Mappa le classi\n    class_mapping = {category['id']: category['name'] for category in data['categories']}\n    nc = len(class_mapping)  # Numero di classi\n\n    # Crea le cartelle per il dataset\n    train_images_dir = os.path.join(output_dir, 'train', 'images')\n    val_images_dir = os.path.join(output_dir, 'val', 'images')\n    test_images_dir = os.path.join(output_dir, 'test', 'images')\n\n    train_labels_dir = os.path.join(output_dir, 'train', 'labels')\n    val_labels_dir = os.path.join(output_dir, 'val', 'labels')\n    test_labels_dir = os.path.join(output_dir, 'test', 'labels')\n    \n    for dir_path in [train_images_dir, val_images_dir, test_images_dir, train_labels_dir, val_labels_dir, test_labels_dir]:\n        os.makedirs(dir_path, exist_ok=True)\n\n    # Dividi le immagini in training, validation, and test\n    images = data['images']\n    random.shuffle(images)\n    total_images = len(images)\n    \n    train_split = int(train_ratio * total_images)\n    val_split = int((train_ratio + val_ratio) * total_images)\n\n    train_images = images[:train_split]\n    val_images = images[train_split:val_split]\n    test_images = images[val_split:]\n\n    # Funzione per copiare le immagini in una cartella specifica\n    def copy_images(image_list, target_dir):\n        for image in tqdm(image_list, desc=f\"Copying images to {target_dir}\", unit=\"image\"):\n            src_path = os.path.join(images_dir, image['file_name'])\n            dst_path = os.path.join(target_dir, image['file_name'])\n            shutil.copy(src_path, dst_path)\n\n    # Copia le immagini nelle rispettive cartelle\n    copy_images(train_images, train_images_dir)\n    copy_images(val_images, val_images_dir)\n    copy_images(test_images, test_images_dir)\n\n    # Converte le annotazioni in formato YOLO e salva nei file di testo\n    def convert_annotations(image, annotations, target_dir):\n        image_id = image['id']\n        image_width = image['width']\n        image_height = image['height']\n        image_name = image['file_name']\n\n        label_file_path = os.path.join(target_dir, f\"{image_name.replace('.jpg', '.txt')}\")\n        label_dir = os.path.dirname(label_file_path)\n\n        # Crea la cartella se non esiste\n        os.makedirs(label_dir, exist_ok=True)\n\n        with open(label_file_path, 'w') as label_file:\n            for annotation in annotations:\n                if annotation['image_id'] == image_id:\n                    category_id = annotation['category_id']\n                    xmin, ymin, xmax, ymax = annotation['bbox']\n\n                    # Normalizza le coordinate\n                    x_center = (xmin + xmax) / 2 / image_width\n                    y_center = (ymin + ymax) / 2 / image_height\n                    width = (xmax - xmin) / image_width\n                    height = (ymax - ymin) / image_height\n\n                    # Scrivi nel file di annotazione\n                    label_file.write(f\"{category_id} {x_center} {y_center} {width} {height}\\n\")\n\n    # Converte le annotazioni per ogni immagine e le salva nelle cartelle appropriate\n    def process_images(image_list, target_dir, label_target_dir):\n        for image in tqdm(image_list, desc=f\"Converting annotations\", unit=\"image\"):\n            annotations = [annotation for annotation in data['annotations'] if annotation['image_id'] == image['id']]\n            convert_annotations(image, annotations, label_target_dir)\n\n    # Processa le immagini per training, validation e test\n    process_images(train_images, 'train', train_labels_dir)\n    process_images(val_images, 'val', val_labels_dir)\n    process_images(test_images, 'test', test_labels_dir)\n        \n    # Crea il file YAML per YOLO\n    yaml_content = f\"\"\"path: {input_dir}\ntrain: {train_dir_out}  # train images\nval: {val_dir_out}  # val images\ntest: {test_dir_out}  # test images\n\n# Classes\nnc: {nc}  # number of classes\nnames:\n\"\"\"\n    # Aggiungi le classi al file YAML\n    for idx, class_name in class_mapping.items():\n        yaml_content += f\"  {int(idx)}: {class_name}\\n\"  # Assicurati che l'indice sia numerico senza virgolette\n\n    # Scrivi il file YAML\n    with open(os.path.join(output_dir, 'dataset.yaml'), 'w') as yaml_file:\n        yaml_file.write(yaml_content.strip())\n\n    print(\"Conversione e split completati.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:54:49.182025Z","iopub.execute_input":"2025-01-02T23:54:49.182403Z","iopub.status.idle":"2025-01-02T23:54:49.198670Z","shell.execute_reply.started":"2025-01-02T23:54:49.182334Z","shell.execute_reply":"2025-01-02T23:54:49.197604Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"convert_json_to_yolo(\n    json_path=new_coco_json_pth,\n    images_dir=img_fldr,\n    output_dir=out_dataset_pth,\n    input_dir=yolo_dataset_pth,\n    train_dir_out=train_img,\n    val_dir_out=val_img,\n    test_dir_out=test_img,\n    train_ratio=0.8,\n    val_ratio=0.1,\n    test_ratio=0.1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T23:54:49.200221Z","iopub.execute_input":"2025-01-02T23:54:49.200703Z","iopub.status.idle":"2025-01-03T00:58:47.820800Z","shell.execute_reply.started":"2025-01-02T23:54:49.200654Z","shell.execute_reply":"2025-01-03T00:58:47.818741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Nome del file zip da creare\nzip_file_name = \"YOLO_dataset.zip\"\n\n# Elenco di file e cartelle da includere nello zip\nitems_to_zip = [\n    \"test\",\n    \"train\",\n    \"val\",\n    \"dataset.yaml\",\n]\n\n# Funzione per aggiungere file e cartelle allo zip\ndef zip_folder(zipf, folder_path, base_folder=\"\"):\n    for root, _, files in os.walk(folder_path):\n        for file in files:\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, base_folder)\n            zipf.write(file_path, arcname)\n\n# Creazione dello zip\nwith zipfile.ZipFile(zip_file_name, 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n    for item in items_to_zip:\n        if os.path.exists(item):  # Verifica che il file o la cartella esista\n            if os.path.isdir(item):  # Se è una cartella, aggiungi tutto il contenuto\n                zip_folder(zipf, item, out_dataset_pth)\n            else:  # Se è un file, aggiungilo direttamente\n                zipf.write(item)\n        else:\n            print(f\"Elemento non trovato: {item}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T00:59:05.566630Z","iopub.execute_input":"2025-01-03T00:59:05.567125Z","iopub.status.idle":"2025-01-03T01:00:29.840972Z","shell.execute_reply.started":"2025-01-03T00:59:05.567085Z","shell.execute_reply":"2025-01-03T01:00:29.839486Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Check Yaml","metadata":{}},{"cell_type":"code","source":"def analyze_yolo_dataset(yaml_path):\n    # Carica il file YAML\n    with open(yaml_path, 'r') as f:\n        data = yaml.safe_load(f)\n\n    # Estraggo le informazioni dal file YAML\n    base_path = data['path']\n    sets = ['train', 'val', 'test']\n    stats = {}\n    \n    total_images = 0\n    total_bboxes = Counter()\n    class_names = data['names']\n\n    for dataset_set in sets:\n        images_path = os.path.join(base_path, dataset_set)\n        labels_path = os.path.join(base_path, dataset_set, 'labels')\n\n        # Controlla se le directory esistono\n        if not os.path.exists(images_path) or not os.path.exists(labels_path):\n            print(f\"Directory per il set '{dataset_set}' non trovata.\")\n            continue\n\n        # Conta immagini\n        image_files = [f for f in os.listdir(images_path) if f.endswith(('.jpg'))]\n        num_images = len(image_files)\n        total_images += num_images\n        \n        stats[dataset_set] = {\"images\": num_images, \"bbox\": Counter()}\n\n        # Conta bounding box con tqdm\n        print(f\"Analizzando {dataset_set}...\")\n        for label_file in tqdm(os.listdir(labels_path), desc=f\"Contando bbox in {dataset_set}\", unit=\"file\"):\n            label_path = os.path.join(labels_path, label_file)\n            with open(label_path, 'r') as f:\n                lines = f.readlines()\n                for line in lines:\n                    class_id = line.split()[0]  # La classe è il primo elemento della riga\n                    stats[dataset_set][\"bbox\"][class_id] += 1\n                    total_bboxes[class_id] += 1\n\n    return stats, total_images, total_bboxes, class_names\n\n# Funzione per mostrare i risultati con le percentuali calcolate per set\ndef print_stats(stats, total_images, total_bboxes, class_names):\n    print(\"\\n--- ANALISI COMPLESSIVA ---\")\n    print(f\"Totale immagini: {total_images}\")\n    print(f\"Distribuzione complessiva delle categorie:\")\n    \n    # Ordina le classi in base al numero di bbox, dal più grande al più piccolo\n    sorted_bboxes = sorted(total_bboxes.items(), key=lambda x: x[1], reverse=True)\n    \n    for class_id, count in sorted_bboxes:\n        percentage = (count / sum(total_bboxes.values())) * 100\n        print(f\"  Classe {class_names[int(class_id)]} ({class_id}): {count} bbox ({percentage:.2f}%)\")\n    \n    print(\"\\n--- ANALISI PER SET ---\")\n    \n    total_bboxes_all_sets = 0  # Per calcolare il totale complessivo dei bbox\n    for dataset_set, data in stats.items():\n        images_percentage = (data['images'] / total_images) * 100 if total_images > 0 else 0\n        print(f\"\\n--- {dataset_set.upper()} ---\")\n        print(f\"Numero di immagini: {data['images']} ({images_percentage:.2f}%)\")\n        print(\"Distribuzione categorie:\")\n        \n        # Calcola il totale dei bbox per ogni set\n        total_bboxes_in_set = sum(data['bbox'].values())\n        total_bboxes_all_sets += total_bboxes_in_set  # Aggiungi al totale complessivo\n        \n        # Ordina le classi per ogni set in base al numero di bbox\n        sorted_set_bboxes = sorted(data['bbox'].items(), key=lambda x: x[1], reverse=True)\n        \n        for class_id, count in sorted_set_bboxes:\n            percentage = (count / total_bboxes_in_set) * 100 if total_bboxes_in_set > 0 else 0\n            print(f\"  Classe {class_names[int(class_id)]} ({class_id}): {count} bbox ({percentage:.2f}%)\")\n        \n        print(\"Totale bounding box:\", total_bboxes_in_set, f\"({(total_bboxes_in_set / sum(total_bboxes.values())) * 100:.2f}%)\")\n\n    # Aggiungi la percentuale per il totale complessivo dei bounding box\n    print(\"\\n--- TOTALE COMPLESSIVO ---\")\n    print(f\"Totale bounding box: {total_bboxes_all_sets}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Esegui analisi\nstats, total_images, total_bboxes, class_names = analyze_yolo_dataset(dataset_yaml)\nprint_stats(stats, total_images, total_bboxes, class_names)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# YoloV11","metadata":{}},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"# Pretrained Model\nmodel = YOLO('yolo11n.pt') \n\n# Configurazione del training\nresults = model.train(\n    data=dataset_yaml,     # Path al file YAML del dataset\n    epochs=100,            # Numero di epoche\n    batch=16,              # Dimensione del batch\n    imgsz=640,             # Dimensione delle immagini (640x640)\n    lr0=0.01,              # Learning rate iniziale\n    lrf=0.1,               # Fattore di decay del learning rate ((riduce da 0.01 a 0.001))\n    save=True,             # Salva i pesi migliori\n    #optimizer='AdamW',    \n    optimizer = 'SGD',\n    momentum=0.9,          # Momentum ottimizzato\n    freeze=[0, 1, 2]       # Congela i primi tre livelli (backbone)\n    #project='my_model_results'  # si può personalizzare la directory di salvataggio dei pesi\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T12:54:54.616838Z","iopub.execute_input":"2025-01-04T12:54:54.617237Z","iopub.status.idle":"2025-01-04T14:13:44.131577Z","shell.execute_reply.started":"2025-01-04T12:54:54.617204Z","shell.execute_reply":"2025-01-04T14:13:44.129717Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.57 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/input/yolodataset-xview/dataset.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=[0, 1, 2], multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.1, momentum=0.9, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train4\nOverriding model.yaml nc=80 with nc=11\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    432817  ultralytics.nn.modules.head.Detect           [11, [64, 128, 256]]          \nYOLO11n summary: 319 layers, 2,591,985 parameters, 2,591,969 gradients, 6.5 GFLOPs\n\nTransferred 448/499 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train4', view at http://localhost:6006/\nFreezing layer 'model.0.conv.weight'\nFreezing layer 'model.0.bn.weight'\nFreezing layer 'model.0.bn.bias'\nFreezing layer 'model.1.conv.weight'\nFreezing layer 'model.1.bn.weight'\nFreezing layer 'model.1.bn.bias'\nFreezing layer 'model.2.cv1.conv.weight'\nFreezing layer 'model.2.cv1.bn.weight'\nFreezing layer 'model.2.cv1.bn.bias'\nFreezing layer 'model.2.cv2.conv.weight'\nFreezing layer 'model.2.cv2.bn.weight'\nFreezing layer 'model.2.cv2.bn.bias'\nFreezing layer 'model.2.m.0.cv1.conv.weight'\nFreezing layer 'model.2.m.0.cv1.bn.weight'\nFreezing layer 'model.2.m.0.cv1.bn.bias'\nFreezing layer 'model.2.m.0.cv2.conv.weight'\nFreezing layer 'model.2.m.0.cv2.bn.weight'\nFreezing layer 'model.2.m.0.cv2.bn.bias'\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/yolodataset-xview/train/labels... 36712 images, 11847 backgrounds, 0 corrupt: 100%|██████████| 36712/36712 [00:45<00:00, 810.47it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1449_960_1280.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1832_0_0.jpg: 69 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1832_0_1600.jpg: 36 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1832_0_1920.jpg: 44 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1832_0_2240.jpg: 43 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1832_0_2560.jpg: 23 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1832_0_320.jpg: 66 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1832_0_640.jpg: 50 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1896_0_0.jpg: 59 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1896_0_1920.jpg: 38 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1896_0_2240.jpg: 68 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1896_0_640.jpg: 87 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1896_0_960.jpg: 33 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_320_0.jpg: 69 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_320_1280.jpg: 48 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_320_2240.jpg: 43 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_320_2560.jpg: 23 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_320_640.jpg: 50 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_320_960.jpg: 33 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_960_0.jpg: 59 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_960_1600.jpg: 21 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_960_1920.jpg: 38 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_960_2240.jpg: 68 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_960_2560.jpg: 75 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_960_320.jpg: 96 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_960_640.jpg: 87 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_960_960.jpg: 33 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2032_0_1280.jpg: 22 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2032_0_1600.jpg: 24 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2032_0_1920.jpg: 25 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2032_0_2240.jpg: 33 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2032_0_2560.jpg: 34 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2032_0_320.jpg: 7 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2064_0_1280.jpg: 12 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2064_0_1600.jpg: 11 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2064_0_1920.jpg: 12 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2064_0_2240.jpg: 18 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_320_1280.jpg: 22 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_320_1920.jpg: 25 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_320_2560.jpg: 34 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_320_320.jpg: 7 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_320_640.jpg: 26 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_320_960.jpg: 19 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_640_1280.jpg: 12 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_640_1920.jpg: 12 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_640_2240.jpg: 18 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_640_2560.jpg: 27 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2230_320_0.jpg: 5 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_532_0_2240.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_532_0_2560.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_532_0_320.jpg: 14 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_596_0_1280.jpg: 10 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_596_0_1920.jpg: 6 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_5_320_320.jpg: 14 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_5_960_1280.jpg: 10 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_5_960_1920.jpg: 6 duplicate labels removed\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/yolodataset-xview/train is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/yolodataset-xview/val/labels... 4589 images, 1496 backgrounds, 0 corrupt: 100%|██████████| 4589/4589 [00:05<00:00, 828.48it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/val/images/img_1832_0_960.jpg: 33 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/val/images/img_1896_0_1600.jpg: 21 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/val/images/img_1896_0_2560.jpg: 75 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/val/images/img_18_320_1600.jpg: 36 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/val/images/img_2032_0_640.jpg: 26 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/val/images/img_2032_0_960.jpg: 19 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/val/images/img_20_640_1600.jpg: 11 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/val/images/img_223_0_3200.jpg: 5 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/val/images/img_5_320_2240.jpg: 2 duplicate labels removed\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/yolodataset-xview/val is not writeable, cache not saved.\nPlotting labels to runs/detect/train4/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/detect/train4\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      1/100      4.86G      1.813      2.176      1.572         98        640: 100%|██████████| 2295/2295 [06:25<00:00,  5.95it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:36<00:00,  3.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.445      0.229      0.177     0.0803\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      2/100      5.01G      1.788      1.792      1.536        131        640: 100%|██████████| 2295/2295 [06:17<00:00,  6.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:38<00:00,  3.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.372      0.293      0.236      0.109\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      3/100      7.12G      1.804      1.763      1.545        107        640: 100%|██████████| 2295/2295 [06:16<00:00,  6.09it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:36<00:00,  3.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.286      0.315      0.245      0.114\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      4/100      5.26G      1.799      1.727      1.549         46        640: 100%|██████████| 2295/2295 [06:22<00:00,  6.00it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:36<00:00,  3.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.348      0.326      0.291       0.14\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      5/100       4.4G      1.781      1.668       1.54        140        640: 100%|██████████| 2295/2295 [06:20<00:00,  6.03it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:36<00:00,  3.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.374      0.351      0.323      0.157\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      6/100      8.41G      1.762      1.638      1.532         65        640: 100%|██████████| 2295/2295 [06:17<00:00,  6.07it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.579      0.349      0.337      0.167\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      7/100       4.7G      1.753      1.606      1.526        136        640: 100%|██████████| 2295/2295 [06:16<00:00,  6.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.588      0.376      0.362      0.182\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      8/100      6.93G      1.742      1.581      1.522        117        640: 100%|██████████| 2295/2295 [06:11<00:00,  6.17it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.605      0.382      0.377      0.183\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      9/100      5.27G      1.733      1.558      1.514         91        640: 100%|██████████| 2295/2295 [06:10<00:00,  6.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:36<00:00,  4.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.622      0.381      0.384      0.193\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     10/100         5G      1.729      1.539      1.508        104        640: 100%|██████████| 2295/2295 [06:12<00:00,  6.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.636      0.379      0.396        0.2\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     11/100      4.24G      1.723      1.531      1.509        197        640: 100%|██████████| 2295/2295 [06:14<00:00,  6.13it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.617      0.406      0.404      0.204\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     12/100      3.81G      1.718      1.514       1.51        218        640:  15%|█▌        | 348/2295 [00:56<05:17,  6.12it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolo11n.pt\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Configurazione del training\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_yaml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Path al file YAML del dataset\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Numero di epoche\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Dimensione del batch\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# Dimensione delle immagini (640x640)\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Learning rate iniziale\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlrf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# Fattore di decay del learning rate ((riduce da 0.01 a 0.001))\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# Salva i pesi migliori\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#optimizer='AdamW',    \u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSGD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# Momentum ottimizzato\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# Congela i primi tre livelli (backbone)\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#project='my_model_results'  # si può personalizzare la directory di salvataggio dei pesi\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py:806\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 806\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py:207\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py:380\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp):\n\u001b[1;32m    379\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_batch(batch)\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m world_size\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py:111\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03mPerform forward pass of the model for either training or inference.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    (torch.Tensor): Loss if x is a dict (training), or network predictions (inference).\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py:292\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_criterion()\n\u001b[0;32m--> 292\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m preds\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(preds, batch)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py:112\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py:130\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py:151\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 151\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    152\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/modules/block.py:238\u001b[0m, in \u001b[0;36mC2f.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 238\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/modules/block.py:238\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 238\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/modules/block.py:347\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    346\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Applies the YOLO FPN to input data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/modules/conv.py:50\u001b[0m, in \u001b[0;36mConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/activation.py:405\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2104\u001b[0m, in \u001b[0;36msilu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   2102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(silu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[1;32m   2103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m-> 2104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":8},{"cell_type":"markdown","source":"### Creazione zip ","metadata":{}},{"cell_type":"code","source":"# Nome del file zip da creare\nzip_file_name = \"SGD_decay_epoch84.zip\"\n\n# Percorso della cartella da includere nello zip\nfolder_to_zip = \"/kaggle/working/runs/detect/train4\"  \n\n# Funzione per aggiungere file e cartelle allo zip\ndef zip_folder(zipf, folder_path, base_folder=\"\"):\n    for root, _, files in os.walk(folder_path):\n        for file in files:\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, base_folder)  # Percorso relativo per preservare la struttura\n            zipf.write(file_path, arcname)\n\n# Creazione dello zip\nif os.path.exists(folder_to_zip):  # Verifica che la cartella esista\n    with zipfile.ZipFile(zip_file_name, 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n        zip_folder(zipf, folder_to_zip, base_folder=folder_to_zip)\n    print(f\"Archivio zip creato: {zip_file_name}\")\nelse:\n    print(f\"Cartella non trovata: {folder_to_zip}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T22:40:43.530963Z","iopub.execute_input":"2025-01-04T22:40:43.531808Z","iopub.status.idle":"2025-01-04T22:40:44.500687Z","shell.execute_reply.started":"2025-01-04T22:40:43.531771Z","shell.execute_reply":"2025-01-04T22:40:44.499786Z"}},"outputs":[{"name":"stdout","text":"Archivio zip creato: SGD_decay_epoch84.zip\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### Riprendere addestramento da pesi salvati","metadata":{}},{"cell_type":"code","source":"# Carica il modello con i pesi precedenti\nmodel = YOLO('/kaggle/input/sgd_decay/pytorch/default/1/last.pt') \n\n# Configura il training\nresults = model.train(\n    data=dataset_yaml,            # Percorso al dataset YAML\n    epochs=100,                    \n    batch=16,                     # Dimensione del batch\n    imgsz=640,                    # Dimensione delle immagini\n    lr0=0.01,                     # Learning rate iniziale\n    lrf=0.1,                      # Fattore di decay del learning rate (riduce da 0.01 a 0.001)\n    optimizer='SGD',              # Ottimizzatore\n    momentum=0.9,                 # Momentum\n    freeze=[0,1,2],\n    save=True,                    # Salva i nuovi pesi\n    resume=True                   # Indica di riprendere l'addestramento\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T14:30:26.848977Z","iopub.execute_input":"2025-01-04T14:30:26.849698Z","iopub.status.idle":"2025-01-04T22:38:57.373260Z","shell.execute_reply.started":"2025-01-04T14:30:26.849661Z","shell.execute_reply":"2025-01-04T22:38:57.371579Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.57 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/input/sgd_decay/pytorch/default/1/last.pt, data=/kaggle/input/yolodataset-xview/dataset.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=/kaggle/input/sgd_decay/pytorch/default/1/last.pt, amp=True, fraction=1.0, profile=False, freeze=[0, 1, 2], multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.1, momentum=0.9, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train4\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 755k/755k [00:00<00:00, 17.7MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train4', view at http://localhost:6006/\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    432817  ultralytics.nn.modules.head.Detect           [11, [64, 128, 256]]          \nYOLO11n summary: 319 layers, 2,591,985 parameters, 2,591,969 gradients, 6.5 GFLOPs\n\nTransferred 499/499 items from pretrained weights\nFreezing layer 'model.0.conv.weight'\nFreezing layer 'model.0.bn.weight'\nFreezing layer 'model.0.bn.bias'\nFreezing layer 'model.1.conv.weight'\nFreezing layer 'model.1.bn.weight'\nFreezing layer 'model.1.bn.bias'\nFreezing layer 'model.2.cv1.conv.weight'\nFreezing layer 'model.2.cv1.bn.weight'\nFreezing layer 'model.2.cv1.bn.bias'\nFreezing layer 'model.2.cv2.conv.weight'\nFreezing layer 'model.2.cv2.bn.weight'\nFreezing layer 'model.2.cv2.bn.bias'\nFreezing layer 'model.2.m.0.cv1.conv.weight'\nFreezing layer 'model.2.m.0.cv1.bn.weight'\nFreezing layer 'model.2.m.0.cv1.bn.bias'\nFreezing layer 'model.2.m.0.cv2.conv.weight'\nFreezing layer 'model.2.m.0.cv2.bn.weight'\nFreezing layer 'model.2.m.0.cv2.bn.bias'\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5.35M/5.35M [00:00<00:00, 74.7MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/yolodataset-xview/train/labels... 36712 images, 11847 backgrounds, 0 corrupt: 100%|██████████| 36712/36712 [02:49<00:00, 216.87it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1449_960_1280.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1832_0_0.jpg: 69 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1832_0_1600.jpg: 36 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1832_0_1920.jpg: 44 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1832_0_2240.jpg: 43 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1832_0_2560.jpg: 23 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1832_0_320.jpg: 66 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1832_0_640.jpg: 50 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1896_0_0.jpg: 59 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1896_0_1920.jpg: 38 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1896_0_2240.jpg: 68 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1896_0_640.jpg: 87 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_1896_0_960.jpg: 33 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_320_0.jpg: 69 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_320_1280.jpg: 48 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_320_2240.jpg: 43 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_320_2560.jpg: 23 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_320_640.jpg: 50 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_320_960.jpg: 33 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_960_0.jpg: 59 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_960_1600.jpg: 21 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_960_1920.jpg: 38 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_960_2240.jpg: 68 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_960_2560.jpg: 75 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_960_320.jpg: 96 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_960_640.jpg: 87 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_18_960_960.jpg: 33 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2032_0_1280.jpg: 22 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2032_0_1600.jpg: 24 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2032_0_1920.jpg: 25 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2032_0_2240.jpg: 33 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2032_0_2560.jpg: 34 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2032_0_320.jpg: 7 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2064_0_1280.jpg: 12 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2064_0_1600.jpg: 11 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2064_0_1920.jpg: 12 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2064_0_2240.jpg: 18 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_320_1280.jpg: 22 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_320_1920.jpg: 25 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_320_2560.jpg: 34 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_320_320.jpg: 7 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_320_640.jpg: 26 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_320_960.jpg: 19 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_640_1280.jpg: 12 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_640_1920.jpg: 12 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_640_2240.jpg: 18 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_20_640_2560.jpg: 27 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_2230_320_0.jpg: 5 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_532_0_2240.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_532_0_2560.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_532_0_320.jpg: 14 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_596_0_1280.jpg: 10 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_596_0_1920.jpg: 6 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_5_320_320.jpg: 14 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_5_960_1280.jpg: 10 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/train/images/img_5_960_1920.jpg: 6 duplicate labels removed\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/yolodataset-xview/train is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.24 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/yolodataset-xview/val/labels... 4589 images, 1496 backgrounds, 0 corrupt: 100%|██████████| 4589/4589 [00:21<00:00, 209.72it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/val/images/img_1832_0_960.jpg: 33 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/val/images/img_1896_0_1600.jpg: 21 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/val/images/img_1896_0_2560.jpg: 75 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/val/images/img_18_320_1600.jpg: 36 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/val/images/img_2032_0_640.jpg: 26 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/val/images/img_2032_0_960.jpg: 19 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/val/images/img_20_640_1600.jpg: 11 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/val/images/img_223_0_3200.jpg: 5 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/yolodataset-xview/val/images/img_5_320_2240.jpg: 2 duplicate labels removed\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/yolodataset-xview/val is not writeable, cache not saved.\nPlotting labels to runs/detect/train4/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\nResuming training /kaggle/input/sgd_decay/pytorch/default/1/last.pt from epoch 12 to 100 total epochs\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/detect/train4\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     12/100       4.7G      1.714      1.506      1.502         98        640: 100%|██████████| 2295/2295 [06:09<00:00,  6.22it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:36<00:00,  3.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.618       0.42      0.418      0.211\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     13/100      4.94G      1.711      1.504      1.496        131        640: 100%|██████████| 2295/2295 [06:05<00:00,  6.27it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.635      0.419      0.426      0.214\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     14/100      7.07G      1.709      1.498      1.495        107        640: 100%|██████████| 2295/2295 [06:04<00:00,  6.30it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:36<00:00,  3.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.662       0.42      0.437      0.224\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     15/100      5.24G      1.704      1.483      1.492         46        640: 100%|██████████| 2295/2295 [06:07<00:00,  6.24it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:36<00:00,  3.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.551      0.444      0.439      0.226\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     16/100      4.33G      1.704      1.476      1.491        140        640: 100%|██████████| 2295/2295 [06:07<00:00,  6.25it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:36<00:00,  3.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.581      0.438      0.445      0.228\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     17/100      8.34G      1.695      1.473       1.49         65        640: 100%|██████████| 2295/2295 [05:59<00:00,  6.38it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:36<00:00,  3.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.582      0.436      0.447      0.229\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     18/100      4.63G      1.695      1.465      1.486        136        640: 100%|██████████| 2295/2295 [05:59<00:00,  6.39it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.607      0.445      0.456      0.235\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     19/100      6.87G      1.689      1.459      1.483        117        640: 100%|██████████| 2295/2295 [05:59<00:00,  6.39it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.575       0.46      0.462      0.238\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     20/100       5.2G      1.686      1.449       1.48         91        640: 100%|██████████| 2295/2295 [06:05<00:00,  6.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:36<00:00,  3.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.594      0.463      0.466      0.242\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     21/100      4.93G      1.685       1.44      1.477        104        640: 100%|██████████| 2295/2295 [05:58<00:00,  6.40it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.599       0.46      0.464      0.243\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     22/100      4.19G      1.683      1.439      1.479        197        640: 100%|██████████| 2295/2295 [06:01<00:00,  6.35it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075       0.62      0.444      0.468      0.245\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     23/100      5.34G      1.684      1.444      1.479        124        640: 100%|██████████| 2295/2295 [05:59<00:00,  6.39it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.615      0.445      0.473      0.247\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     24/100      5.24G      1.682      1.438      1.478         87        640: 100%|██████████| 2295/2295 [06:03<00:00,  6.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.603      0.465      0.479       0.25\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     25/100      6.03G      1.681      1.428      1.473        141        640: 100%|██████████| 2295/2295 [06:05<00:00,  6.28it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.597      0.474      0.481      0.252\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     26/100      5.99G      1.679      1.426      1.473         81        640: 100%|██████████| 2295/2295 [06:05<00:00,  6.29it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.595      0.473      0.483      0.253\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     27/100      4.63G      1.678      1.427      1.471        183        640: 100%|██████████| 2295/2295 [06:09<00:00,  6.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.604      0.471      0.481      0.252\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     28/100      7.47G      1.673      1.416      1.471        192        640: 100%|██████████| 2295/2295 [06:04<00:00,  6.30it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.609      0.466      0.482      0.254\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     29/100         5G      1.673      1.418      1.469         86        640: 100%|██████████| 2295/2295 [06:03<00:00,  6.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.592      0.482      0.484      0.254\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     30/100      6.16G      1.673      1.415      1.468        272        640: 100%|██████████| 2295/2295 [06:01<00:00,  6.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.593      0.481      0.485      0.256\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     31/100      7.11G       1.67      1.406      1.465        195        640: 100%|██████████| 2295/2295 [06:04<00:00,  6.29it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:36<00:00,  3.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075       0.61      0.472      0.486      0.256\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     32/100      5.93G      1.666      1.399      1.462         85        640: 100%|██████████| 2295/2295 [06:04<00:00,  6.30it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.602      0.476      0.486      0.256\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     33/100      4.44G      1.667      1.403      1.463         70        640: 100%|██████████| 2295/2295 [06:00<00:00,  6.37it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.598      0.479      0.487      0.257\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     34/100      4.31G      1.664      1.397      1.461         94        640: 100%|██████████| 2295/2295 [06:02<00:00,  6.33it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:34<00:00,  4.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.494      0.502      0.487      0.257\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     35/100      6.76G      1.662      1.395      1.459        196        640: 100%|██████████| 2295/2295 [06:04<00:00,  6.30it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:34<00:00,  4.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.493      0.502      0.488      0.258\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     36/100      5.16G      1.663       1.39       1.46        160        640: 100%|██████████| 2295/2295 [06:02<00:00,  6.32it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.497      0.503      0.489      0.259\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     37/100       6.6G      1.663      1.393      1.459        157        640: 100%|██████████| 2295/2295 [06:02<00:00,  6.34it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.631      0.461      0.488      0.258\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     38/100      6.54G      1.656      1.389      1.456        110        640: 100%|██████████| 2295/2295 [06:03<00:00,  6.31it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.507      0.508      0.492      0.261\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     39/100      5.41G      1.658      1.387      1.456        192        640: 100%|██████████| 2295/2295 [06:05<00:00,  6.27it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:34<00:00,  4.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.526      0.502      0.493      0.261\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     40/100      6.88G      1.656      1.382      1.456        123        640: 100%|██████████| 2295/2295 [06:00<00:00,  6.37it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.533      0.504      0.493      0.263\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     41/100      3.67G      1.654      1.381      1.453        105        640: 100%|██████████| 2295/2295 [05:58<00:00,  6.41it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.553      0.501      0.495      0.263\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     42/100      6.43G      1.654      1.375       1.45        153        640: 100%|██████████| 2295/2295 [05:56<00:00,  6.44it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.562        0.5      0.495      0.264\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     43/100      7.91G      1.649      1.372       1.45        224        640: 100%|██████████| 2295/2295 [05:58<00:00,  6.41it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:34<00:00,  4.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.567      0.498      0.497      0.265\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     44/100      6.11G       1.65      1.368       1.45         43        640: 100%|██████████| 2295/2295 [05:56<00:00,  6.44it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.572      0.497      0.497      0.265\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     45/100      4.87G       1.65      1.365      1.448         82        640: 100%|██████████| 2295/2295 [05:55<00:00,  6.46it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.575      0.497      0.498      0.265\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     46/100      6.24G      1.646      1.365      1.448        132        640: 100%|██████████| 2295/2295 [05:54<00:00,  6.47it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.578      0.497      0.501      0.267\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     47/100      5.58G      1.645      1.364      1.445        103        640: 100%|██████████| 2295/2295 [05:56<00:00,  6.43it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.582      0.494      0.503      0.268\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     48/100      4.64G      1.644      1.359      1.445         93        640: 100%|██████████| 2295/2295 [05:55<00:00,  6.45it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.586      0.494      0.504      0.269\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     49/100      5.56G      1.642      1.356      1.444         69        640: 100%|██████████| 2295/2295 [05:56<00:00,  6.44it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:34<00:00,  4.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075       0.59      0.492      0.505       0.27\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     50/100      5.02G      1.642      1.352      1.441        126        640: 100%|██████████| 2295/2295 [05:55<00:00,  6.46it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:34<00:00,  4.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075       0.59      0.492      0.506      0.271\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     51/100      7.17G      1.643      1.351       1.44         63        640: 100%|██████████| 2295/2295 [05:55<00:00,  6.45it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.591      0.493      0.514      0.276\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     52/100       5.7G       1.64      1.346       1.44        104        640: 100%|██████████| 2295/2295 [05:56<00:00,  6.44it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:34<00:00,  4.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.598      0.491      0.515      0.277\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     53/100      6.32G      1.637      1.346      1.438        242        640: 100%|██████████| 2295/2295 [05:56<00:00,  6.44it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.599      0.491      0.517      0.278\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     54/100      5.94G      1.639      1.343      1.438        119        640: 100%|██████████| 2295/2295 [05:57<00:00,  6.42it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.597      0.495      0.517      0.279\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     55/100      4.23G      1.636      1.336      1.438         23        640: 100%|██████████| 2295/2295 [05:55<00:00,  6.45it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:34<00:00,  4.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.599      0.496      0.518      0.279\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     56/100      5.86G      1.635       1.34      1.437        156        640: 100%|██████████| 2295/2295 [05:59<00:00,  6.38it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.606      0.493      0.519       0.28\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     57/100      6.95G      1.635      1.336      1.436        106        640: 100%|██████████| 2295/2295 [05:56<00:00,  6.43it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.617      0.494       0.52      0.281\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     58/100      4.71G      1.631      1.336      1.433        210        640: 100%|██████████| 2295/2295 [05:55<00:00,  6.46it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.614      0.496      0.522      0.282\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     59/100      6.59G      1.633      1.336      1.436        134        640: 100%|██████████| 2295/2295 [05:57<00:00,  6.41it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.603      0.504      0.523      0.282\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     60/100      7.22G      1.632      1.332      1.432        115        640: 100%|██████████| 2295/2295 [05:57<00:00,  6.43it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.596      0.507      0.524      0.283\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     61/100      6.89G      1.628      1.328      1.428         93        640: 100%|██████████| 2295/2295 [05:59<00:00,  6.39it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.596      0.504      0.525      0.284\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     62/100      6.46G      1.627      1.328      1.432        111        640: 100%|██████████| 2295/2295 [05:58<00:00,  6.41it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.598      0.506      0.526      0.283\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     63/100      4.75G      1.626      1.323      1.425        128        640: 100%|██████████| 2295/2295 [06:04<00:00,  6.30it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.601      0.508      0.527      0.285\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     64/100      4.63G      1.627      1.322      1.427        114        640: 100%|██████████| 2295/2295 [05:59<00:00,  6.38it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.599      0.509      0.528      0.286\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     65/100      5.31G      1.626      1.319      1.425        102        640: 100%|██████████| 2295/2295 [05:58<00:00,  6.40it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.601      0.507       0.53      0.287\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     66/100      5.17G      1.625      1.319      1.424         97        640: 100%|██████████| 2295/2295 [05:57<00:00,  6.41it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.598      0.507       0.53      0.287\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     67/100      6.74G      1.623      1.318      1.423        162        640: 100%|██████████| 2295/2295 [05:57<00:00,  6.43it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:34<00:00,  4.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.594      0.511       0.53      0.287\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     68/100      6.37G      1.619      1.313      1.422         58        640: 100%|██████████| 2295/2295 [05:56<00:00,  6.43it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.596      0.511      0.531      0.288\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     69/100      5.41G       1.62      1.309       1.42        142        640: 100%|██████████| 2295/2295 [05:57<00:00,  6.41it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.601      0.511      0.532      0.289\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     70/100      5.85G      1.621      1.308      1.421        130        640: 100%|██████████| 2295/2295 [05:58<00:00,  6.40it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075        0.6      0.515      0.533      0.289\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     71/100      4.88G       1.62      1.302      1.419        136        640: 100%|██████████| 2295/2295 [05:56<00:00,  6.43it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075        0.6      0.515      0.534       0.29\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     72/100      5.61G      1.617      1.307      1.418         88        640: 100%|██████████| 2295/2295 [05:55<00:00,  6.46it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:34<00:00,  4.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.602      0.515      0.534      0.291\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     73/100      5.84G      1.617      1.303      1.417        140        640: 100%|██████████| 2295/2295 [05:53<00:00,  6.49it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.603      0.515      0.535      0.292\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     74/100      7.65G      1.618        1.3      1.418         82        640: 100%|██████████| 2295/2295 [05:53<00:00,  6.49it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.597      0.519      0.536      0.292\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     75/100         4G      1.614      1.297      1.414        101        640: 100%|██████████| 2295/2295 [05:54<00:00,  6.48it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.602      0.516      0.537      0.293\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     76/100      6.47G      1.614      1.294      1.412        149        640: 100%|██████████| 2295/2295 [06:03<00:00,  6.32it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:34<00:00,  4.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.594      0.518      0.539      0.294\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     77/100      6.33G      1.611      1.294      1.412        113        640: 100%|██████████| 2295/2295 [05:56<00:00,  6.44it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:34<00:00,  4.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.592      0.519       0.54      0.295\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     78/100      6.14G      1.609      1.293      1.412         94        640: 100%|██████████| 2295/2295 [05:59<00:00,  6.39it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:34<00:00,  4.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.596      0.522      0.541      0.295\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     79/100      6.13G      1.609      1.285      1.408         83        640: 100%|██████████| 2295/2295 [05:57<00:00,  6.42it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.594      0.524      0.541      0.296\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     80/100      5.71G      1.612      1.285      1.409        219        640: 100%|██████████| 2295/2295 [05:57<00:00,  6.42it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075       0.59      0.527      0.536      0.291\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     81/100      5.69G      1.605      1.278      1.406        111        640: 100%|██████████| 2295/2295 [05:56<00:00,  6.43it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.587       0.53      0.544      0.297\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     82/100      5.64G      1.605      1.279      1.406         70        640: 100%|██████████| 2295/2295 [06:04<00:00,  6.30it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.592      0.527      0.538      0.292\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     83/100      5.45G      1.605      1.279      1.407         90        640: 100%|██████████| 2295/2295 [06:01<00:00,  6.35it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:35<00:00,  4.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075      0.597      0.524      0.539      0.293\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     84/100      6.31G      1.603      1.274      1.406         77        640: 100%|██████████| 2295/2295 [06:01<00:00,  6.35it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 144/144 [00:34<00:00,  4.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       4589      48075        0.6      0.523      0.541      0.294\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"     85/100      3.85G      1.582      1.242      1.393        146        640:   7%|▋         | 162/2295 [00:25<05:51,  6.07it/s]/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n     85/100      3.85G      1.582      1.242      1.393        146        640:   7%|▋         | 162/2295 [00:25<05:38,  6.30it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/sgd_decay/pytorch/default/1/last.pt\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Configura il training\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_yaml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Percorso al dataset YAML\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                    \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;66;43;03m# Dimensione del batch\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# Dimensione delle immagini\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;66;43;03m# Learning rate iniziale\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlrf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                      \u001b[49m\u001b[38;5;66;43;03m# Fattore di decay del learning rate (riduce da 0.01 a 0.001)\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSGD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Ottimizzatore\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# Momentum\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# Salva i nuovi pesi\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m                   \u001b[49m\u001b[38;5;66;43;03m# Indica di riprendere l'addestramento\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py:806\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 806\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py:207\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py:408\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n\u001b[1;32m    407\u001b[0m     loss_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 408\u001b[0m     \u001b[43mpbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_description\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%11s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%11.4g\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_length\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m.3g\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mG\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (GB) GPU memory util\u001b[39;49;00m\n\u001b[1;32m    413\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloss_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# losses\u001b[39;49;00m\n\u001b[1;32m    414\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# batch size, i.e. 8\u001b[39;49;00m\n\u001b[1;32m    415\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# imgsz, i.e 640\u001b[39;49;00m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mplots \u001b[38;5;129;01mand\u001b[39;00m ni \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_idx:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1382\u001b[0m, in \u001b[0;36mtqdm.set_description\u001b[0;34m(self, desc, refresh)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ema_miniters \u001b[38;5;241m=\u001b[39m EMA(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmoothing)\n\u001b[1;32m   1380\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m-> 1382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_description\u001b[39m(\u001b[38;5;28mself\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, refresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1383\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;124;03m    Set/modify description of the progress bar.\u001b[39;00m\n\u001b[1;32m   1385\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;124;03m        Forces refresh [default: True].\u001b[39;00m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdesc \u001b[38;5;241m=\u001b[39m desc \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m desc \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":6},{"cell_type":"markdown","source":"## Validazione","metadata":{}},{"cell_type":"code","source":"model = YOLO('/kaggle/working/runs/detect/train/weights/best.pt') # carica i pesi salvati (senza si considera il modello dell'ultima epoca)\nmodel.eval()\nresults = model.val(data=dataset_yaml) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Test","metadata":{}},{"cell_type":"code","source":"model = YOLO('/kaggle/working/runs/detect/train4/weights/best.pt')\nresults = model.predict(test_img, imgsz=416, conf = 0.25, save = True, project = out_dataset_pth, verbose = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T22:41:15.216069Z","iopub.execute_input":"2025-01-04T22:41:15.216635Z","iopub.status.idle":"2025-01-04T22:42:30.782533Z","shell.execute_reply.started":"2025-01-04T22:41:15.216599Z","shell.execute_reply":"2025-01-04T22:42:30.780985Z"}},"outputs":[{"name":"stdout","text":"\nWARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\nerrors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n\nExample:\n    results = model(source=..., stream=True)  # generator of Results objects\n    for r in results:\n        boxes = r.boxes  # Boxes object for bbox outputs\n        masks = r.masks  # Masks object for segment masks outputs\n        probs = r.probs  # Class probabilities for classification outputs\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/runs/detect/train4/weights/best.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m416\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mout_dataset_pth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py:558\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/predictor.py:173\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:57\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m             \u001b[38;5;66;03m# Pass the last request to the generator and get its response\u001b[39;00m\n\u001b[1;32m     56\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 57\u001b[0m                 response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# We let the exceptions raised above by the generator's `.throw` or\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# `.send` methods bubble up to our caller, except for StopIteration\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# The generator informed us that it is done: take whatever its\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# returned value (if any) was and indicate that we're done too\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# by returning it (see docs for python's return-statement).\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/predictor.py:259\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 259\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/predictor.py:143\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    139\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    142\u001b[0m )\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/autobackend.py:524\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[0;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[0;32m--> 524\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py:112\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py:130\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py:151\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 151\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    152\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/modules/block.py:1041\u001b[0m, in \u001b[0;36mC2PSA.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Processes the input tensor 'x' through a series of PSA blocks and returns the transformed tensor.\"\"\"\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m a, b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39msplit((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 1041\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat((a, b), \u001b[38;5;241m1\u001b[39m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/modules/block.py:955\u001b[0m, in \u001b[0;36mPSABlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    954\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Executes a forward pass through PSABlock, applying attention and feed-forward layers to the input tensor.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 955\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(x)\n\u001b[1;32m    956\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(x)\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/modules/block.py:919\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    917\u001b[0m attn \u001b[38;5;241m=\u001b[39m attn\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    918\u001b[0m x \u001b[38;5;241m=\u001b[39m (v \u001b[38;5;241m@\u001b[39m attn\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mview(B, C, H, W) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpe(v\u001b[38;5;241m.\u001b[39mreshape(B, C, H, W))\n\u001b[0;32m--> 919\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/modules/conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution and activation without batch normalization.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"#visualizza un'immagine di test con box e etichette predette\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# Specifica il percorso dell'immagine\npath = \"predict/img_102_0_2560.jpg\"\n\n# Carica l'immagine\nimg = mpimg.imread(path)\n\n# Mostra l'immagine\nplt.imshow(img)\nplt.axis('off')  # Rimuove gli assi\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}