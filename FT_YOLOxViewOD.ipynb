{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":10182328,"datasetId":6242793}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library import","metadata":{}},{"cell_type":"code","source":"import os\nimport subprocess\nimport time\n\nimport yaml\nfrom sklearn.model_selection import GroupKFold\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nfrom tqdm import tqdm\nimport torch.nn as nn\n\nfrom pathlib import Path\nimport json\nfrom collections import defaultdict, Counter\nimport random\nimport random\nimport shutil\nfrom tqdm import tqdm\nimport zipfile","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T19:22:43.794732Z","iopub.execute_input":"2025-01-02T19:22:43.795786Z","iopub.status.idle":"2025-01-02T19:22:43.801989Z","shell.execute_reply.started":"2025-01-02T19:22:43.795742Z","shell.execute_reply":"2025-01-02T19:22:43.800689Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"# Path","metadata":{}},{"cell_type":"code","source":"COCO_JSON_NM = 'COCO_annotations_new.json'\nOUT_COCO_JSON_NM = 'mod_COCO_annotations.json'\nOUT_IMAGE_FLDR_NM = 'images'\nTRAIN_NM = 'train'\nVAL_NM = 'val'\nTEST_NM = 'test'\nLABEL_NM = 'labels'\nYAML = 'dataset.yaml'\nRANDOM_SEED = 2023\n\nin_dataset_pth = Path('/kaggle/input/our-xview-dataset')\nyolo_dataset_pth = Path('/kaggle/input/yolodataset-xview')\nout_dataset_pth = Path('/kaggle/working/')\nimg_fldr = Path(f'/kaggle/input/our-xview-dataset/{OUT_IMAGE_FLDR_NM}')\n\ncoco_json_pth = in_dataset_pth / COCO_JSON_NM\nnew_coco_json_pth = out_dataset_pth / OUT_COCO_JSON_NM\n\nlabels_pth = yolo_dataset_pth / LABEL_NM\ntrain_img = yolo_dataset_pth / TRAIN_NM\nval_img = yolo_dataset_pth / VAL_NM\ntest_img = yolo_dataset_pth / TEST_NM\ntrain_txt = labels_pth / TRAIN_NM\nval_txt = labels_pth / VAL_NM\ntest_txt = labels_pth / TEST_NM\ndataset_yaml = yolo_dataset_pth / YAML","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T19:52:39.071514Z","iopub.execute_input":"2025-01-02T19:52:39.072647Z","iopub.status.idle":"2025-01-02T19:52:39.079632Z","shell.execute_reply.started":"2025-01-02T19:52:39.072600Z","shell.execute_reply":"2025-01-02T19:52:39.078343Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# Pulizia dell'output per cartelle specifiche\ndef clean_output(output_dir):\n    if output_dir.exists() and output_dir.is_dir():\n        for item in output_dir.iterdir():\n            if item.is_dir():\n                shutil.rmtree(item)  # Rimuove la sotto-cartella\n            else:\n                item.unlink()  # Rimuove il file\n        print(f\"Cartella {output_dir} pulita.\")\n    else:\n        print(f\"Cartella {output_dir} non trovata. Nessuna azione necessaria.\")\n\n# Pulisce la cartella di output prima di avviare il processo\nclean_output(out_dataset_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T18:31:53.945854Z","iopub.execute_input":"2025-01-02T18:31:53.946770Z","iopub.status.idle":"2025-01-02T18:31:55.870925Z","shell.execute_reply.started":"2025-01-02T18:31:53.946715Z","shell.execute_reply":"2025-01-02T18:31:55.869867Z"}},"outputs":[{"name":"stdout","text":"Cartella /kaggle/working pulita.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# Utility","metadata":{}},{"cell_type":"code","source":"def load_json(file_path):\n    \"\"\"\n    Carica un file JSON dal percorso specificato.\n\n    :param file_path: Percorso al file JSON da caricare.\n    :return: Dati contenuti nel file JSON (come dizionario o lista).\n    \"\"\"\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T18:32:29.028029Z","iopub.execute_input":"2025-01-02T18:32:29.028904Z","iopub.status.idle":"2025-01-02T18:32:29.034022Z","shell.execute_reply.started":"2025-01-02T18:32:29.028860Z","shell.execute_reply":"2025-01-02T18:32:29.032956Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# COCO Preprocessing","metadata":{}},{"cell_type":"code","source":"def process_custom_coco_json(input_path, output_path):\n    \"\"\"\n    Funzione per processare un JSON COCO in formato personalizzato.\n    \"\"\"\n    # Leggi il JSON dal file di input\n    data = load_json(input_path)\n\n    # Ottieni e correggi il formato delle categorie\n    raw_categories = data.get('categories', [])\n    categories = []\n \n    for category in tqdm(raw_categories, desc=\"Processing Categories\"):\n        for id_str, name in category.items():\n            try:\n                categories.append({\"id\": int(id_str), \"name\": name})\n            except ValueError:\n                print(f\"Errore nel parsing della categoria: {category}\")\n \n    # Trova la categoria \"Aircraft\" con ID 0\n    aircraft_category = next((cat for cat in categories if cat['id'] == 0 and cat['name'] == \"Aircraft\"), None)\n    if aircraft_category:\n        aircraft_category['id'] = 11  # Cambia l'ID della categoria \"Aircraft\" a 11\n \n    # Aggiungi la categoria \"background\" con ID 0 se non esiste\n    if not any(cat['id'] == 0 for cat in categories):\n        categories.append({\"id\": 0, \"name\": \"background\"})\n \n    # Preprocessa le annotazioni in un dizionario per immagini\n    image_annotations_dict = {}\n    for annotation in tqdm(data.get('annotations', []), desc=\"Building Image Annotations Dictionary\"):\n        image_id = annotation['image_id']\n        if image_id not in image_annotations_dict:\n            image_annotations_dict[image_id] = []\n        image_annotations_dict[image_id].append(annotation)\n \n    # Elenco di annotazioni da mantenere (solo quelle valide)\n    valid_annotations = []\n    annotations_to_remove = set()\n \n    # Controllo dei bounding box\n    for annotation in tqdm(data.get('annotations', []), desc=\"Processing Annotations\"):\n        if annotation['category_id'] == 0:  # Se √® Aircraft\n            annotation['category_id'] = 11\n        \n        # Converte il formato del bbox\n        if isinstance(annotation['bbox'], str):\n            annotation['bbox'] = json.loads(annotation['bbox'])\n        \n        x, y, width, height = annotation['bbox']\n        xmin, xmax = x, x + width\n        ymin, ymax = y, y + height\n        \n        # Verifica che xmin < xmax e ymin < ymax, e che la larghezza e altezza siano sufficienti\n        if xmin >= xmax or ymin >= ymax or width <= 10 or height <= 10:\n            annotations_to_remove.add(annotation['id'])\n        else:\n            annotation['bbox'] = [xmin, ymin, xmax, ymax]\n            valid_annotations.append(annotation)\n \n    # Rimuovi le annotazioni non valide\n    data['annotations'] = valid_annotations\n \n    # Verifica se ci sono immagini senza annotazioni (usando il dizionario delle annotazioni)\n    new_annotations = []\n    for image in tqdm(data.get('images', []), desc=\"Processing Images\"):\n        if image['id'] not in image_annotations_dict:  # Se l'immagine non ha annotazioni\n            # Aggiungi la categoria \"background\"\n            new_annotation = {\n                'id': len(data['annotations']) + len(new_annotations),\n                'image_id': image['id'],\n                'category_id': 0,  # Categoria background con ID 0\n                'area': image['width'] * image['height'],\n                'bbox': [0.0, 0.0, image['width'], image['height']],  # Background con bbox che copre tutta l'immagine\n                'iscrowd': 0\n            }\n            new_annotations.append(new_annotation)\n \n    # Aggiungi le nuove annotazioni al JSON originale\n    data['annotations'].extend(new_annotations)\n \n    # Aggiorna le categorie nel JSON\n    data['categories'] = categories\n \n    # Scrivi il JSON modificato nel file di output\n    with open(output_path, 'w') as f:\n        json.dump(data, f, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T18:32:30.439156Z","iopub.execute_input":"2025-01-02T18:32:30.439609Z","iopub.status.idle":"2025-01-02T18:32:30.453549Z","shell.execute_reply.started":"2025-01-02T18:32:30.439569Z","shell.execute_reply":"2025-01-02T18:32:30.452286Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"process_custom_coco_json(coco_json_pth, new_coco_json_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T18:32:33.125356Z","iopub.execute_input":"2025-01-02T18:32:33.125830Z","iopub.status.idle":"2025-01-02T18:32:48.014631Z","shell.execute_reply.started":"2025-01-02T18:32:33.125793Z","shell.execute_reply":"2025-01-02T18:32:48.013385Z"}},"outputs":[{"name":"stderr","text":"Processing Categories: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00<00:00, 106062.86it/s]\nBuilding Image Annotations Dictionary: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 669983/669983 [00:00<00:00, 1973788.56it/s]\nProcessing Annotations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 669983/669983 [00:04<00:00, 148759.98it/s]\nProcessing Images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45891/45891 [00:00<00:00, 777392.41it/s]\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"### Category Check","metadata":{}},{"cell_type":"code","source":"def count_bounding_boxes(json_path):\n    \"\"\"\n    Conta il numero di bounding box per ogni categoria in un file COCO JSON.\n\n    Args:\n        json_path (str): Percorso del file JSON.\n\n    Returns:\n        list: Elenco di tuple con ID categoria, nome categoria e numero di bounding box.\n    \"\"\"\n    # Carica il file JSON\n    coco_data = load_json(json_path)\n\n    # Estrarre i dati principali\n    annotations = coco_data.get(\"annotations\", [])\n    categories = coco_data.get(\"categories\", [])\n\n    # Mappare id di categoria ai nomi delle categorie\n    category_id_to_name = {category[\"id\"]: category[\"name\"] for category in categories}\n\n    # Contare i bounding box per categoria\n    bbox_counts = defaultdict(int)\n    for annotation in annotations:\n        category_id = annotation[\"category_id\"]\n        bbox_counts[category_id] += 1\n\n    # Creare un elenco dei risultati\n    results = [\n        (cat_id, category_id_to_name.get(cat_id, \"Unknown\"), count)\n        for cat_id, count in bbox_counts.items()\n    ]\n    \n    # Ordinare i risultati in ordine decrescente per numero di bounding box\n    results.sort(key=lambda x: x[2], reverse=True)\n    \n    # Stampare i risultati\n    for cat_id, category_name, count in results:\n        print(f\"Categoria ID {cat_id} ('{category_name}'): {count} bounding box\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T18:32:48.016493Z","iopub.execute_input":"2025-01-02T18:32:48.016882Z","iopub.status.idle":"2025-01-02T18:32:48.024868Z","shell.execute_reply.started":"2025-01-02T18:32:48.016846Z","shell.execute_reply":"2025-01-02T18:32:48.023775Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"count_bounding_boxes(new_coco_json_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T18:32:48.026077Z","iopub.execute_input":"2025-01-02T18:32:48.026386Z","iopub.status.idle":"2025-01-02T18:32:50.635275Z","shell.execute_reply.started":"2025-01-02T18:32:48.026356Z","shell.execute_reply":"2025-01-02T18:32:50.633868Z"}},"outputs":[{"name":"stdout","text":"Categoria ID 6 ('Building'): 343313 bounding box\nCategoria ID 1 ('Passenger Vehicle'): 93827 bounding box\nCategoria ID 2 ('Truck'): 24582 bounding box\nCategoria ID 0 ('background'): 13691 bounding box\nCategoria ID 4 ('Maritime Vessel'): 5161 bounding box\nCategoria ID 5 ('Engineering Vehicle'): 4728 bounding box\nCategoria ID 9 ('Shipping Container'): 4558 bounding box\nCategoria ID 3 ('Railway Vehicle'): 3691 bounding box\nCategoria ID 8 ('Storage Tank'): 1743 bounding box\nCategoria ID 11 ('Aircraft'): 1561 bounding box\nCategoria ID 10 ('Pylon'): 415 bounding box\nCategoria ID 7 ('Helipad'): 136 bounding box\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# JSON to YOLO","metadata":{}},{"cell_type":"code","source":"def convert_json_to_yolo(json_path, images_dir, output_dir, input_dir, train_dir_out, val_dir_out, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n    # Carica il file JSON\n    with open(json_path) as f:\n        data = json.load(f)\n\n    # Mappa le classi\n    class_mapping = {category['id']: category['name'] for category in data['categories']}\n    nc = len(class_mapping)  # Numero di classi\n\n    # Crea le cartelle per il dataset\n    train_dir = os.path.join(output_dir, 'train')\n    val_dir = os.path.join(output_dir, 'val')\n    test_dir = os.path.join(output_dir, 'test')\n    labels_dir = os.path.join(output_dir, 'labels')\n    \n    for dir_path in [train_dir, val_dir, test_dir, labels_dir]:\n        os.makedirs(dir_path, exist_ok=True)\n\n    # Dividi le immagini in training, validation, and test\n    images = data['images']\n    random.shuffle(images)\n    total_images = len(images)\n    \n    train_split = int(train_ratio * total_images)\n    val_split = int((train_ratio + val_ratio) * total_images)\n\n    train_images = images[:train_split]\n    val_images = images[train_split:val_split]\n    test_images = images[val_split:]\n\n    # Funzione per copiare le immagini in una cartella specifica\n    def copy_images(image_list, target_dir):\n        for image in tqdm(image_list, desc=f\"Copying images to {target_dir}\", unit=\"image\"):\n            src_path = os.path.join(images_dir, image['file_name'])\n            dst_path = os.path.join(target_dir, image['file_name'])\n            shutil.copy(src_path, dst_path)\n\n    # Copia le immagini nelle rispettive cartelle\n    copy_images(train_images, train_dir)\n    copy_images(val_images, val_dir)\n    copy_images(test_images, test_dir)\n\n    # Converte le annotazioni in formato YOLO e salva nei file di testo\n    def convert_annotations(image, annotations, target_dir):\n        image_id = image['id']\n        image_width = image['width']\n        image_height = image['height']\n        image_name = image['file_name']\n\n        label_file_path = os.path.join(target_dir, f\"{image_name.replace('.jpg', '.txt')}\")\n        label_dir = os.path.dirname(label_file_path)\n\n        # Crea la cartella se non esiste\n        os.makedirs(label_dir, exist_ok=True)\n\n        with open(label_file_path, 'w') as label_file:\n            for annotation in annotations:\n                if annotation['image_id'] == image_id:\n                    category_id = annotation['category_id']\n                    xmin, ymin, xmax, ymax = annotation['bbox']\n\n                    # Normalizza le coordinate\n                    x_center = (xmin + xmax) / 2 / image_width\n                    y_center = (ymin + ymax) / 2 / image_height\n                    width = (xmax - xmin) / image_width\n                    height = (ymax - ymin) / image_height\n\n                    # Scrivi nel file di annotazione\n                    label_file.write(f\"{category_id} {x_center} {y_center} {width} {height}\\n\")\n\n    # Converte le annotazioni per ogni immagine e le salva nelle cartelle appropriate\n    def process_images(image_list, target_dir, label_target_dir):\n        for image in tqdm(image_list, desc=f\"Converting annotations\", unit=\"image\"):\n            annotations = [annotation for annotation in data['annotations'] if annotation['image_id'] == image['id']]\n            convert_annotations(image, annotations, os.path.join(label_target_dir, target_dir))\n\n    # Processa le immagini per training, validation e test\n    process_images(train_images, 'train', labels_dir)\n    process_images(val_images, 'val', labels_dir)\n    process_images(test_images, 'test', labels_dir)\n\n    # Crea il file YAML per YOLO\n    \n    yaml_content = f\"\"\"\n    path: {input_dir}\n    train: {train_dir_out}\n    val: {val_dir_out}\n    test: {test_dir_out}\n    nc: {nc}\n    names: {list(class_mapping.values())}\n    \"\"\"\n    with open(os.path.join(output_dir, 'dataset.yaml'), 'w') as yaml_file:\n        yaml_file.write(yaml_content.strip())\n\n    print(\"Conversione e split completati.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T19:53:32.804273Z","iopub.execute_input":"2025-01-02T19:53:32.804704Z","iopub.status.idle":"2025-01-02T19:53:32.819402Z","shell.execute_reply.started":"2025-01-02T19:53:32.804668Z","shell.execute_reply":"2025-01-02T19:53:32.818386Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"convert_json_to_yolo(\n    json_path=new_coco_json_pth,\n    images_dir=img_fldr,\n    output_dir=out_dataset_pth,\n    input_dir=yolo_dataset_pth\n    train_dir_out=train_img,\n    val_dir_out=val_img,\n    test_dir_out=test_img,\n    train_ratio=0.8,\n    val_ratio=0.1,\n    test_ratio=0.1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T18:32:50.660104Z","iopub.execute_input":"2025-01-02T18:32:50.660522Z","iopub.status.idle":"2025-01-02T19:21:21.732650Z","shell.execute_reply.started":"2025-01-02T18:32:50.660406Z","shell.execute_reply":"2025-01-02T19:21:21.731629Z"}},"outputs":[{"name":"stderr","text":"Copying images to /kaggle/working/YOLO/train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36712/36712 [00:51<00:00, 715.44image/s]\nCopying images to /kaggle/working/YOLO/val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4589/4589 [00:06<00:00, 677.41image/s]\nCopying images to /kaggle/working/YOLO/test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4590/4590 [00:06<00:00, 703.25image/s]\nConverting annotations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36712/36712 [37:54<00:00, 16.14image/s]\nConverting annotations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4589/4589 [04:44<00:00, 16.15image/s]\nConverting annotations: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4590/4590 [04:44<00:00, 16.14image/s]\n","output_type":"stream"},{"name":"stdout","text":"Conversione e split completati.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Nome del file zip da creare\nzip_file_name = \"YOLO_dataset.zip\"\n\n# Elenco di file e cartelle da includere nello zip\nitems_to_zip = [\n    \"labels\",\n    \"test\",\n    \"train\",\n    \"val\",\n    \"dataset.yaml\",\n]\n\n# Funzione per aggiungere file e cartelle allo zip\ndef zip_folder(zipf, folder_path, base_folder=\"\"):\n    for root, _, files in os.walk(folder_path):\n        for file in files:\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, base_folder)\n            zipf.write(file_path, arcname)\n\n# Creazione dello zip\nwith zipfile.ZipFile(zip_file_name, 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n    for item in items_to_zip:\n        if os.path.exists(item):  # Verifica che il file o la cartella esista\n            if os.path.isdir(item):  # Se √® una cartella, aggiungi tutto il contenuto\n                zip_folder(zipf, item, out_dataset_pth)\n            else:  # Se √® un file, aggiungilo direttamente\n                zipf.write(item)\n        else:\n            print(f\"Elemento non trovato: {item}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T19:24:11.546615Z","iopub.execute_input":"2025-01-02T19:24:11.546998Z","iopub.status.idle":"2025-01-02T19:25:21.154079Z","shell.execute_reply.started":"2025-01-02T19:24:11.546965Z","shell.execute_reply":"2025-01-02T19:25:21.152818Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"# YoloV11","metadata":{}},{"cell_type":"code","source":"%pip install ultralytics\nimport ultralytics\nultralytics.checks()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T19:42:38.795468Z","iopub.execute_input":"2025-01-02T19:42:38.796557Z","iopub.status.idle":"2025-01-02T19:42:54.658714Z","shell.execute_reply.started":"2025-01-02T19:42:38.796510Z","shell.execute_reply":"2025-01-02T19:42:54.657786Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.56 üöÄ Python-3.10.14 torch-2.4.0+cpu CPU (Intel Xeon 2.20GHz)\nSetup complete ‚úÖ (4 CPUs, 31.4 GB RAM, 6037.6/8062.4 GB disk)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# Load a model\nmodel = YOLO('yolo11n.pt')  # load a pretrained model (recommended for training)\n\n# Use the model\nresults = model.train(data=dataset_yaml, epochs=3)  # train the model\nresults = model.val()  # evaluate model performance on the validation set","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T19:43:11.518172Z","iopub.execute_input":"2025-01-02T19:43:11.518575Z","iopub.status.idle":"2025-01-02T19:43:11.880942Z","shell.execute_reply.started":"2025-01-02T19:43:11.518540Z","shell.execute_reply":"2025-01-02T19:43:11.879343Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.56 üöÄ Python-3.10.14 torch-2.4.0+cpu CPU (Intel Xeon 2.20GHz)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/kaggle/input/yolodataset-xview/YOLO/dataset.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mScannerError\u001b[0m                              Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py:562\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    561\u001b[0m }:\n\u001b[0;32m--> 562\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/data/utils.py:279\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# Read YAML\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43myaml_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappend_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# dictionary\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m# Checks\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/utils/__init__.py:490\u001b[0m, in \u001b[0;36myaml_load\u001b[0;34m(file, append_filename)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;66;03m# Add YAML filename to dict and return\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43myaml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m {}  \u001b[38;5;66;03m# always return a dict (yaml.safe_load() may return None for empty files)\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m append_filename:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/yaml/__init__.py:125\u001b[0m, in \u001b[0;36msafe_load\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03mParse the first YAML document in a stream\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03mand produce the corresponding Python object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03mto be safe for untrusted input.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSafeLoader\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/yaml/__init__.py:81\u001b[0m, in \u001b[0;36mload\u001b[0;34m(stream, Loader)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/yaml/constructor.py:49\u001b[0m, in \u001b[0;36mBaseConstructor.get_single_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_single_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Ensure that the stream contains a single document and construct it.\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_single_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/yaml/composer.py:36\u001b[0m, in \u001b[0;36mComposer.get_single_node\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(StreamEndEvent):\n\u001b[0;32m---> 36\u001b[0m     document \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Ensure that the stream contains no more documents.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/yaml/composer.py:55\u001b[0m, in \u001b[0;36mComposer.compose_document\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Compose the root node.\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Drop the DOCUMENT-END event.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/yaml/composer.py:84\u001b[0m, in \u001b[0;36mComposer.compose_node\u001b[0;34m(self, parent, index)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_event(MappingStartEvent):\n\u001b[0;32m---> 84\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mascend_resolver()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/yaml/composer.py:127\u001b[0m, in \u001b[0;36mComposer.compose_mapping_node\u001b[0;34m(self, anchor)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manchors[anchor] \u001b[38;5;241m=\u001b[39m node\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMappingEndEvent\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m#key_event = self.peek_event()\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     item_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/yaml/parser.py:98\u001b[0m, in \u001b[0;36mParser.check_event\u001b[0;34m(self, *choices)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate:\n\u001b[0;32m---> 98\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/yaml/parser.py:428\u001b[0m, in \u001b[0;36mParser.parse_block_mapping_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_block_mapping_key\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 428\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKeyToken\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    429\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_token()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/yaml/scanner.py:116\u001b[0m, in \u001b[0;36mScanner.check_token\u001b[0;34m(self, *choices)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneed_more_tokens():\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_more_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/yaml/scanner.py:223\u001b[0m, in \u001b[0;36mScanner.fetch_more_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_value():\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Is it an alias?\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/yaml/scanner.py:577\u001b[0m, in \u001b[0;36mScanner.fetch_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_simple_key:\n\u001b[0;32m--> 577\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ScannerError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmapping values are not allowed here\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    579\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mark())\n\u001b[1;32m    581\u001b[0m \u001b[38;5;66;03m# If this value starts a new block mapping, we need to add\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;66;03m# BLOCK-MAPPING-START.  It will be detected as an error later by\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;66;03m# the parser.\u001b[39;00m\n","\u001b[0;31mScannerError\u001b[0m: mapping values are not allowed here\n  in \"<unicode string>\", line 2, column 10:\n        train: /kaggle/working/YOLO/train\n             ^","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[34], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolo11n.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# load a pretrained model (recommended for training)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Use the model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_yaml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mval()  \u001b[38;5;66;03m# evaluate model performance on the validation set\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py:800\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    798\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[0;32m--> 800\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py:133\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m check_model_file_from_stem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel)  \u001b[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(LOCAL_RANK):  \u001b[38;5;66;03m# avoid auto-downloading dataset multiple times\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Optimization utils init\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py:566\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(emojis(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclean_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m error ‚ùå \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m], data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mRuntimeError\u001b[0m: Dataset '/kaggle/input/yolodataset-xview/YOLO/dataset.yaml' error ‚ùå mapping values are not allowed here\n  in \"<unicode string>\", line 2, column 10:\n        train: /kaggle/working/YOLO/train\n             ^"],"ename":"RuntimeError","evalue":"Dataset '/kaggle/input/yolodataset-xview/YOLO/dataset.yaml' error ‚ùå mapping values are not allowed here\n  in \"<unicode string>\", line 2, column 10:\n        train: /kaggle/working/YOLO/train\n             ^","output_type":"error"}],"execution_count":34}]}