{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":10182328,"datasetId":6242793}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library import","metadata":{}},{"cell_type":"code","source":"import os\nimport subprocess\nimport time\n\nimport yaml\nfrom sklearn.model_selection import GroupKFold\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nfrom tqdm import tqdm\nimport torch.nn as nn\n\nfrom pathlib import Path\nimport json\nfrom collections import defaultdict, Counter\nimport random\nimport random\nimport shutil\nfrom tqdm import tqdm\nimport zipfile","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:20:27.361276Z","iopub.execute_input":"2025-01-02T22:20:27.362199Z","iopub.status.idle":"2025-01-02T22:20:27.367029Z","shell.execute_reply.started":"2025-01-02T22:20:27.362162Z","shell.execute_reply":"2025-01-02T22:20:27.366047Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"%pip install ultralytics\nimport ultralytics\nultralytics.checks()\nfrom ultralytics import YOLO","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Path","metadata":{}},{"cell_type":"code","source":"COCO_JSON_NM = 'COCO_annotations_new.json'\nOUT_COCO_JSON_NM = 'mod_COCO_annotations.json'\nOUT_IMAGE_FLDR_NM = 'images'\nTRAIN_NM = 'train'\nVAL_NM = 'val'\nTEST_NM = 'test'\nLABEL_NM = 'labels'\nYAML = 'dataset.yaml'\nRANDOM_SEED = 2023\n\nin_dataset_pth = Path('/kaggle/input/our-xview-dataset')\nyolo_dataset_pth = Path('/kaggle/input/yolodataset-xview')\nout_dataset_pth = Path('/kaggle/working/')\nimg_fldr = Path(f'/kaggle/input/our-xview-dataset/{OUT_IMAGE_FLDR_NM}')\n\ncoco_json_pth = in_dataset_pth / COCO_JSON_NM\nnew_coco_json_pth = out_dataset_pth / OUT_COCO_JSON_NM\n\nlabels_pth = yolo_dataset_pth / LABEL_NM\ntrain_img = yolo_dataset_pth / TRAIN_NM\nval_img = yolo_dataset_pth / VAL_NM\ntest_img = yolo_dataset_pth / TEST_NM\ntrain_txt = labels_pth / TRAIN_NM\nval_txt = labels_pth / VAL_NM\ntest_txt = labels_pth / TEST_NM\ndataset_yaml = yolo_dataset_pth / YAML","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:20:29.259497Z","iopub.execute_input":"2025-01-02T22:20:29.259880Z","iopub.status.idle":"2025-01-02T22:20:29.266007Z","shell.execute_reply.started":"2025-01-02T22:20:29.259826Z","shell.execute_reply":"2025-01-02T22:20:29.265130Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Pulizia dell'output per cartelle specifiche\ndef clean_output(output_dir):\n    if output_dir.exists() and output_dir.is_dir():\n        for item in output_dir.iterdir():\n            if item.is_dir():\n                shutil.rmtree(item)  # Rimuove la sotto-cartella\n            else:\n                item.unlink()  # Rimuove il file\n        print(f\"Cartella {output_dir} pulita.\")\n    else:\n        print(f\"Cartella {output_dir} non trovata. Nessuna azione necessaria.\")\n\n# Pulisce la cartella di output prima di avviare il processo\nclean_output(out_dataset_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:20:32.791075Z","iopub.execute_input":"2025-01-02T22:20:32.791443Z","iopub.status.idle":"2025-01-02T22:20:32.827440Z","shell.execute_reply.started":"2025-01-02T22:20:32.791413Z","shell.execute_reply":"2025-01-02T22:20:32.826605Z"}},"outputs":[{"name":"stdout","text":"Cartella /kaggle/working pulita.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# Utility","metadata":{}},{"cell_type":"code","source":"def load_json(file_path):\n    \"\"\"\n    Carica un file JSON dal percorso specificato.\n\n    :param file_path: Percorso al file JSON da caricare.\n    :return: Dati contenuti nel file JSON (come dizionario o lista).\n    \"\"\"\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T22:20:35.088759Z","iopub.execute_input":"2025-01-02T22:20:35.089132Z","iopub.status.idle":"2025-01-02T22:20:35.093755Z","shell.execute_reply.started":"2025-01-02T22:20:35.089101Z","shell.execute_reply":"2025-01-02T22:20:35.092832Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"# COCO Preprocessing","metadata":{}},{"cell_type":"code","source":"def process_custom_coco_json(input_path, output_path):\n    \"\"\"\n    Funzione per processare un JSON COCO in formato personalizzato.\n    \"\"\"\n    # Leggi il JSON dal file di input\n    data = load_json(input_path)\n\n    # Ottieni e correggi il formato delle categorie\n    raw_categories = data.get('categories', [])\n    categories = []\n \n    for category in tqdm(raw_categories, desc=\"Processing Categories\"):\n        for id_str, name in category.items():\n            try:\n                categories.append({\"id\": int(id_str), \"name\": name})\n            except ValueError:\n                print(f\"Errore nel parsing della categoria: {category}\")\n \n    # Trova la categoria \"Aircraft\" con ID 0\n    aircraft_category = next((cat for cat in categories if cat['id'] == 0 and cat['name'] == \"Aircraft\"), None)\n    if aircraft_category:\n        aircraft_category['id'] = 11  # Cambia l'ID della categoria \"Aircraft\" a 11\n \n    # Aggiungi la categoria \"background\" con ID 0 se non esiste\n    if not any(cat['id'] == 0 for cat in categories):\n        categories.append({\"id\": 0, \"name\": \"background\"})\n \n    # Preprocessa le annotazioni in un dizionario per immagini\n    image_annotations_dict = {}\n    for annotation in tqdm(data.get('annotations', []), desc=\"Building Image Annotations Dictionary\"):\n        image_id = annotation['image_id']\n        if image_id not in image_annotations_dict:\n            image_annotations_dict[image_id] = []\n        image_annotations_dict[image_id].append(annotation)\n \n    # Elenco di annotazioni da mantenere (solo quelle valide)\n    valid_annotations = []\n    annotations_to_remove = set()\n \n    # Controllo dei bounding box\n    for annotation in tqdm(data.get('annotations', []), desc=\"Processing Annotations\"):\n        if annotation['category_id'] == 0:  # Se è Aircraft\n            annotation['category_id'] = 11\n        \n        # Converte il formato del bbox\n        if isinstance(annotation['bbox'], str):\n            annotation['bbox'] = json.loads(annotation['bbox'])\n        \n        x, y, width, height = annotation['bbox']\n        xmin, xmax = x, x + width\n        ymin, ymax = y, y + height\n        \n        # Verifica che xmin < xmax e ymin < ymax, e che la larghezza e altezza siano sufficienti\n        if xmin >= xmax or ymin >= ymax or width <= 10 or height <= 10:\n            annotations_to_remove.add(annotation['id'])\n        else:\n            annotation['bbox'] = [xmin, ymin, xmax, ymax]\n            valid_annotations.append(annotation)\n \n    # Rimuovi le annotazioni non valide\n    data['annotations'] = valid_annotations\n \n    # Verifica se ci sono immagini senza annotazioni (usando il dizionario delle annotazioni)\n    new_annotations = []\n    for image in tqdm(data.get('images', []), desc=\"Processing Images\"):\n        if image['id'] not in image_annotations_dict:  # Se l'immagine non ha annotazioni\n            # Aggiungi la categoria \"background\"\n            new_annotation = {\n                'id': len(data['annotations']) + len(new_annotations),\n                'image_id': image['id'],\n                'category_id': 0,  # Categoria background con ID 0\n                'area': image['width'] * image['height'],\n                'bbox': [0.0, 0.0, image['width'], image['height']],  # Background con bbox che copre tutta l'immagine\n                'iscrowd': 0\n            }\n            new_annotations.append(new_annotation)\n \n    # Aggiungi le nuove annotazioni al JSON originale\n    data['annotations'].extend(new_annotations)\n \n    # Ordina le categorie per ID\n    categories = sorted(categories, key=lambda x: x['id'])\n    \n    # Aggiorna le categorie nel JSON\n    data['categories'] = categories\n\n \n    # Scrivi il JSON modificato nel file di output\n    with open(output_path, 'w') as f:\n        json.dump(data, f, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T21:57:52.604755Z","iopub.execute_input":"2025-01-02T21:57:52.605445Z","iopub.status.idle":"2025-01-02T21:57:52.617463Z","shell.execute_reply.started":"2025-01-02T21:57:52.605414Z","shell.execute_reply":"2025-01-02T21:57:52.616487Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"process_custom_coco_json(coco_json_pth, new_coco_json_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T21:57:54.338979Z","iopub.execute_input":"2025-01-02T21:57:54.339324Z","iopub.status.idle":"2025-01-02T21:58:07.371032Z","shell.execute_reply.started":"2025-01-02T21:57:54.339295Z","shell.execute_reply":"2025-01-02T21:58:07.370122Z"}},"outputs":[{"name":"stderr","text":"Processing Categories: 100%|██████████| 11/11 [00:00<00:00, 103215.53it/s]\nBuilding Image Annotations Dictionary: 100%|██████████| 669983/669983 [00:00<00:00, 2347633.31it/s]\nProcessing Annotations: 100%|██████████| 669983/669983 [00:03<00:00, 207062.46it/s]\nProcessing Images: 100%|██████████| 45891/45891 [00:00<00:00, 131132.27it/s]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### Category Check","metadata":{}},{"cell_type":"code","source":"def count_bounding_boxes(json_path):\n    \"\"\"\n    Conta il numero di bounding box per ogni categoria in un file COCO JSON.\n\n    Args:\n        json_path (str): Percorso del file JSON.\n\n    Returns:\n        list: Elenco di tuple con ID categoria, nome categoria e numero di bounding box.\n    \"\"\"\n    # Carica il file JSON\n    coco_data = load_json(json_path)\n\n    # Estrarre i dati principali\n    annotations = coco_data.get(\"annotations\", [])\n    categories = coco_data.get(\"categories\", [])\n\n    # Mappare id di categoria ai nomi delle categorie\n    category_id_to_name = {category[\"id\"]: category[\"name\"] for category in categories}\n\n    # Contare i bounding box per categoria\n    bbox_counts = defaultdict(int)\n    for annotation in annotations:\n        category_id = annotation[\"category_id\"]\n        bbox_counts[category_id] += 1\n\n    # Creare un elenco dei risultati\n    results = [\n        (cat_id, category_id_to_name.get(cat_id, \"Unknown\"), count)\n        for cat_id, count in bbox_counts.items()\n    ]\n    \n    # Ordinare i risultati in ordine decrescente per numero di bounding box\n    results.sort(key=lambda x: x[2], reverse=True)\n    \n    # Stampare i risultati\n    for cat_id, category_name, count in results:\n        print(f\"Categoria ID {cat_id} ('{category_name}'): {count} bounding box\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T19:55:35.905358Z","iopub.execute_input":"2025-01-02T19:55:35.906012Z","iopub.status.idle":"2025-01-02T19:55:35.916088Z","shell.execute_reply.started":"2025-01-02T19:55:35.905962Z","shell.execute_reply":"2025-01-02T19:55:35.914845Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"count_bounding_boxes(new_coco_json_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T19:55:35.917491Z","iopub.execute_input":"2025-01-02T19:55:35.917926Z","iopub.status.idle":"2025-01-02T19:55:38.990672Z","shell.execute_reply.started":"2025-01-02T19:55:35.917879Z","shell.execute_reply":"2025-01-02T19:55:38.989556Z"}},"outputs":[{"name":"stdout","text":"Categoria ID 6 ('Building'): 343313 bounding box\nCategoria ID 1 ('Passenger Vehicle'): 93827 bounding box\nCategoria ID 2 ('Truck'): 24582 bounding box\nCategoria ID 0 ('background'): 13691 bounding box\nCategoria ID 4 ('Maritime Vessel'): 5161 bounding box\nCategoria ID 5 ('Engineering Vehicle'): 4728 bounding box\nCategoria ID 9 ('Shipping Container'): 4558 bounding box\nCategoria ID 3 ('Railway Vehicle'): 3691 bounding box\nCategoria ID 8 ('Storage Tank'): 1743 bounding box\nCategoria ID 11 ('Aircraft'): 1561 bounding box\nCategoria ID 10 ('Pylon'): 415 bounding box\nCategoria ID 7 ('Helipad'): 136 bounding box\n","output_type":"stream"}],"execution_count":60},{"cell_type":"markdown","source":"# JSON to YOLO","metadata":{}},{"cell_type":"code","source":"def convert_json_to_yolo(json_path, images_dir, output_dir, input_dir, train_dir_out, val_dir_out, test_dir_out, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n    # Carica il file JSON\n    with open(json_path) as f:\n        data = json.load(f)\n\n    # Mappa le classi\n    class_mapping = {category['id']: category['name'] for category in data['categories']}\n    nc = len(class_mapping)  # Numero di classi\n\n    # Crea le cartelle per il dataset\n    train_dir = os.path.join(output_dir, 'train')\n    val_dir = os.path.join(output_dir, 'val')\n    test_dir = os.path.join(output_dir, 'test')\n    labels_dir = os.path.join(output_dir, 'labels')\n    \n    for dir_path in [train_dir, val_dir, test_dir, labels_dir]:\n        os.makedirs(dir_path, exist_ok=True)\n\n    # Dividi le immagini in training, validation, and test\n    images = data['images']\n    random.shuffle(images)\n    total_images = len(images)\n    \n    train_split = int(train_ratio * total_images)\n    val_split = int((train_ratio + val_ratio) * total_images)\n\n    train_images = images[:train_split]\n    val_images = images[train_split:val_split]\n    test_images = images[val_split:]\n\n    # Funzione per copiare le immagini in una cartella specifica\n    def copy_images(image_list, target_dir):\n        for image in tqdm(image_list, desc=f\"Copying images to {target_dir}\", unit=\"image\"):\n            src_path = os.path.join(images_dir, image['file_name'])\n            dst_path = os.path.join(target_dir, image['file_name'])\n            shutil.copy(src_path, dst_path)\n\n    # Copia le immagini nelle rispettive cartelle\n    copy_images(train_images, train_dir)\n    copy_images(val_images, val_dir)\n    copy_images(test_images, test_dir)\n\n    # Converte le annotazioni in formato YOLO e salva nei file di testo\n    def convert_annotations(image, annotations, target_dir):\n        image_id = image['id']\n        image_width = image['width']\n        image_height = image['height']\n        image_name = image['file_name']\n\n        label_file_path = os.path.join(target_dir, f\"{image_name.replace('.jpg', '.txt')}\")\n        label_dir = os.path.dirname(label_file_path)\n\n        # Crea la cartella se non esiste\n        os.makedirs(label_dir, exist_ok=True)\n\n        with open(label_file_path, 'w') as label_file:\n            for annotation in annotations:\n                if annotation['image_id'] == image_id:\n                    category_id = annotation['category_id']\n                    xmin, ymin, xmax, ymax = annotation['bbox']\n\n                    # Normalizza le coordinate\n                    x_center = (xmin + xmax) / 2 / image_width\n                    y_center = (ymin + ymax) / 2 / image_height\n                    width = (xmax - xmin) / image_width\n                    height = (ymax - ymin) / image_height\n\n                    # Scrivi nel file di annotazione\n                    label_file.write(f\"{category_id} {x_center} {y_center} {width} {height}\\n\")\n\n    # Converte le annotazioni per ogni immagine e le salva nelle cartelle appropriate\n    def process_images(image_list, target_dir, label_target_dir):\n        for image in tqdm(image_list, desc=f\"Converting annotations\", unit=\"image\"):\n            annotations = [annotation for annotation in data['annotations'] if annotation['image_id'] == image['id']]\n            convert_annotations(image, annotations, os.path.join(label_target_dir, target_dir))\n\n    # Processa le immagini per training, validation e test\n    process_images(train_images, 'train', labels_dir)\n    process_images(val_images, 'val', labels_dir)\n    process_images(test_images, 'test', labels_dir)\n\n    # Crea il file YAML per YOLO\n    yaml_content = f\"\"\"path: {input_dir}\ntrain: {train_dir_out}val: {val_dir_out}\ntest: {test_dir_out}\nnc: {nc}\nnames: {list(class_mapping.values())}\"\"\"\n    \n    with open(os.path.join(output_dir, 'dataset.yaml'), 'w') as yaml_file:\n        yaml_file.write(yaml_content.strip())\n\n    print(\"Conversione e split completati.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T21:59:53.712076Z","iopub.execute_input":"2025-01-02T21:59:53.712684Z","iopub.status.idle":"2025-01-02T21:59:53.725465Z","shell.execute_reply.started":"2025-01-02T21:59:53.712651Z","shell.execute_reply":"2025-01-02T21:59:53.724513Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"convert_json_to_yolo(\n    json_path=new_coco_json_pth,\n    images_dir=img_fldr,\n    output_dir=out_dataset_pth,\n    input_dir=yolo_dataset_pth,\n    train_dir_out=train_img,\n    val_dir_out=val_img,\n    test_dir_out=test_img,\n    train_ratio=0.8,\n    val_ratio=0.1,\n    test_ratio=0.1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T19:56:25.324937Z","iopub.execute_input":"2025-01-02T19:56:25.325784Z","iopub.status.idle":"2025-01-02T20:55:58.360147Z","shell.execute_reply.started":"2025-01-02T19:56:25.325742Z","shell.execute_reply":"2025-01-02T20:55:58.359036Z"}},"outputs":[{"name":"stderr","text":"Copying images to /kaggle/working/train: 100%|██████████| 36712/36712 [01:15<00:00, 486.89image/s]\nCopying images to /kaggle/working/val: 100%|██████████| 4589/4589 [00:09<00:00, 496.63image/s]\nCopying images to /kaggle/working/test: 100%|██████████| 4590/4590 [00:08<00:00, 514.80image/s]\nConverting annotations: 100%|██████████| 36712/36712 [46:20<00:00, 13.20image/s]\nConverting annotations: 100%|██████████| 4589/4589 [05:48<00:00, 13.19image/s]\nConverting annotations: 100%|██████████| 4590/4590 [05:47<00:00, 13.22image/s]\n","output_type":"stream"},{"name":"stdout","text":"Conversione e split completati.\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"# Nome del file zip da creare\nzip_file_name = \"YOLO_dataset.zip\"\n\n# Elenco di file e cartelle da includere nello zip\nitems_to_zip = [\n    \"labels\",\n    \"test\",\n    \"train\",\n    \"val\",\n    \"dataset.yaml\",\n]\n\n# Funzione per aggiungere file e cartelle allo zip\ndef zip_folder(zipf, folder_path, base_folder=\"\"):\n    for root, _, files in os.walk(folder_path):\n        for file in files:\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, base_folder)\n            zipf.write(file_path, arcname)\n\n# Creazione dello zip\nwith zipfile.ZipFile(zip_file_name, 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n    for item in items_to_zip:\n        if os.path.exists(item):  # Verifica che il file o la cartella esista\n            if os.path.isdir(item):  # Se è una cartella, aggiungi tutto il contenuto\n                zip_folder(zipf, item, out_dataset_pth)\n            else:  # Se è un file, aggiungilo direttamente\n                zipf.write(item)\n        else:\n            print(f\"Elemento non trovato: {item}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T20:57:04.217058Z","iopub.execute_input":"2025-01-02T20:57:04.217369Z","iopub.status.idle":"2025-01-02T20:58:09.809164Z","shell.execute_reply.started":"2025-01-02T20:57:04.217339Z","shell.execute_reply":"2025-01-02T20:58:09.807697Z"}},"outputs":[],"execution_count":66},{"cell_type":"markdown","source":"# YoloV11","metadata":{}},{"cell_type":"code","source":"# Load a model\nmodel = YOLO('yolo11n.pt')  # load a pretrained model (recommended for training)\n\n# Configurazione del training\nresults = model.train(\n    data=dataset_yaml,     # Path al file YAML del dataset\n    epochs=3,              # Numero di epoche\n    batch=16,              # Dimensione del batch\n    imgsz=320,             # Dimensione delle immagini (320x320)\n    lr0=0.001,             # Learning rate iniziale\n    save=True,             # Salva i pesi migliori\n    verbose=True           # Mostra dettagli nel log\n)\nresults = model.val()  # evaluate model performance on the validation set","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}