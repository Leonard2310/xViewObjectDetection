{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":10182328,"datasetId":6242793}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library import","metadata":{}},{"cell_type":"code","source":"import os\nimport subprocess\nimport time\n\nimport yaml\nfrom sklearn.model_selection import GroupKFold\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nfrom tqdm import tqdm\nimport torch.nn as nn\n\nfrom pathlib import Path\nimport json\nfrom collections import defaultdict, Counter\nimport random\nimport random\nimport shutil\nfrom tqdm import tqdm\nimport zipfile","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T19:22:43.794732Z","iopub.execute_input":"2025-01-02T19:22:43.795786Z","iopub.status.idle":"2025-01-02T19:22:43.801989Z","shell.execute_reply.started":"2025-01-02T19:22:43.795742Z","shell.execute_reply":"2025-01-02T19:22:43.800689Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"# Path","metadata":{}},{"cell_type":"code","source":"COCO_JSON_NM = 'COCO_annotations_new.json'\nOUT_COCO_JSON_NM = 'mod_COCO_annotations.json'\nOUT_IMAGE_FLDR_NM = 'images'\nYOLO_FLDR_NM = 'YOLO'\nRANDOM_SEED = 2023\n\nin_dataset_pth = Path('/kaggle/input/our-xview-dataset')\nout_dataset_pth = Path('/kaggle/working/')\nimg_fldr = Path(f'/kaggle/input/our-xview-dataset/{OUT_IMAGE_FLDR_NM}')\n\ncoco_json_pth = in_dataset_pth / COCO_JSON_NM\nnew_coco_json_pth = out_dataset_pth / OUT_COCO_JSON_NM\n\nyolo_path = out_dataset_pth / YOLO_FLDR_NM\n\ntrain_file = \"/kaggle/input/our-xview-dataset/YOLO_cfg/train.txt\"\nval_file = \"/kaggle/input/our-xview-dataset/YOLO_cfg/val.txt\"\ntest_file = \"/kaggle/input/our-xview-dataset/YOLO_cfg/test.txt\"\ndataset_yaml = \"/kaggle/input/our-xview-dataset/YOLO_cfg/xview_yolo.yaml\" # bisogna modificare i path nel file perchè non si trovano ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T18:18:15.305324Z","iopub.execute_input":"2025-01-02T18:18:15.305791Z","iopub.status.idle":"2025-01-02T18:18:15.312263Z","shell.execute_reply.started":"2025-01-02T18:18:15.305755Z","shell.execute_reply":"2025-01-02T18:18:15.310816Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Pulizia dell'output per cartelle specifiche\ndef clean_output(output_dir):\n    if output_dir.exists() and output_dir.is_dir():\n        for item in output_dir.iterdir():\n            if item.is_dir():\n                shutil.rmtree(item)  # Rimuove la sotto-cartella\n            else:\n                item.unlink()  # Rimuove il file\n        print(f\"Cartella {output_dir} pulita.\")\n    else:\n        print(f\"Cartella {output_dir} non trovata. Nessuna azione necessaria.\")\n\n# Pulisce la cartella di output prima di avviare il processo\nclean_output(out_dataset_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T18:31:53.945854Z","iopub.execute_input":"2025-01-02T18:31:53.946770Z","iopub.status.idle":"2025-01-02T18:31:55.870925Z","shell.execute_reply.started":"2025-01-02T18:31:53.946715Z","shell.execute_reply":"2025-01-02T18:31:55.869867Z"}},"outputs":[{"name":"stdout","text":"Cartella /kaggle/working pulita.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# Utility","metadata":{}},{"cell_type":"code","source":"def load_json(file_path):\n    \"\"\"\n    Carica un file JSON dal percorso specificato.\n\n    :param file_path: Percorso al file JSON da caricare.\n    :return: Dati contenuti nel file JSON (come dizionario o lista).\n    \"\"\"\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T18:32:29.028029Z","iopub.execute_input":"2025-01-02T18:32:29.028904Z","iopub.status.idle":"2025-01-02T18:32:29.034022Z","shell.execute_reply.started":"2025-01-02T18:32:29.028860Z","shell.execute_reply":"2025-01-02T18:32:29.032956Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# COCO Preprocessing","metadata":{}},{"cell_type":"code","source":"def process_custom_coco_json(input_path, output_path):\n    \"\"\"\n    Funzione per processare un JSON COCO in formato personalizzato.\n    \"\"\"\n    # Leggi il JSON dal file di input\n    data = load_json(input_path)\n\n    # Ottieni e correggi il formato delle categorie\n    raw_categories = data.get('categories', [])\n    categories = []\n \n    for category in tqdm(raw_categories, desc=\"Processing Categories\"):\n        for id_str, name in category.items():\n            try:\n                categories.append({\"id\": int(id_str), \"name\": name})\n            except ValueError:\n                print(f\"Errore nel parsing della categoria: {category}\")\n \n    # Trova la categoria \"Aircraft\" con ID 0\n    aircraft_category = next((cat for cat in categories if cat['id'] == 0 and cat['name'] == \"Aircraft\"), None)\n    if aircraft_category:\n        aircraft_category['id'] = 11  # Cambia l'ID della categoria \"Aircraft\" a 11\n \n    # Aggiungi la categoria \"background\" con ID 0 se non esiste\n    if not any(cat['id'] == 0 for cat in categories):\n        categories.append({\"id\": 0, \"name\": \"background\"})\n \n    # Preprocessa le annotazioni in un dizionario per immagini\n    image_annotations_dict = {}\n    for annotation in tqdm(data.get('annotations', []), desc=\"Building Image Annotations Dictionary\"):\n        image_id = annotation['image_id']\n        if image_id not in image_annotations_dict:\n            image_annotations_dict[image_id] = []\n        image_annotations_dict[image_id].append(annotation)\n \n    # Elenco di annotazioni da mantenere (solo quelle valide)\n    valid_annotations = []\n    annotations_to_remove = set()\n \n    # Controllo dei bounding box\n    for annotation in tqdm(data.get('annotations', []), desc=\"Processing Annotations\"):\n        if annotation['category_id'] == 0:  # Se è Aircraft\n            annotation['category_id'] = 11\n        \n        # Converte il formato del bbox\n        if isinstance(annotation['bbox'], str):\n            annotation['bbox'] = json.loads(annotation['bbox'])\n        \n        x, y, width, height = annotation['bbox']\n        xmin, xmax = x, x + width\n        ymin, ymax = y, y + height\n        \n        # Verifica che xmin < xmax e ymin < ymax, e che la larghezza e altezza siano sufficienti\n        if xmin >= xmax or ymin >= ymax or width <= 10 or height <= 10:\n            annotations_to_remove.add(annotation['id'])\n        else:\n            annotation['bbox'] = [xmin, ymin, xmax, ymax]\n            valid_annotations.append(annotation)\n \n    # Rimuovi le annotazioni non valide\n    data['annotations'] = valid_annotations\n \n    # Verifica se ci sono immagini senza annotazioni (usando il dizionario delle annotazioni)\n    new_annotations = []\n    for image in tqdm(data.get('images', []), desc=\"Processing Images\"):\n        if image['id'] not in image_annotations_dict:  # Se l'immagine non ha annotazioni\n            # Aggiungi la categoria \"background\"\n            new_annotation = {\n                'id': len(data['annotations']) + len(new_annotations),\n                'image_id': image['id'],\n                'category_id': 0,  # Categoria background con ID 0\n                'area': image['width'] * image['height'],\n                'bbox': [0.0, 0.0, image['width'], image['height']],  # Background con bbox che copre tutta l'immagine\n                'iscrowd': 0\n            }\n            new_annotations.append(new_annotation)\n \n    # Aggiungi le nuove annotazioni al JSON originale\n    data['annotations'].extend(new_annotations)\n \n    # Aggiorna le categorie nel JSON\n    data['categories'] = categories\n \n    # Scrivi il JSON modificato nel file di output\n    with open(output_path, 'w') as f:\n        json.dump(data, f, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T18:32:30.439156Z","iopub.execute_input":"2025-01-02T18:32:30.439609Z","iopub.status.idle":"2025-01-02T18:32:30.453549Z","shell.execute_reply.started":"2025-01-02T18:32:30.439569Z","shell.execute_reply":"2025-01-02T18:32:30.452286Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"process_custom_coco_json(coco_json_pth, new_coco_json_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T18:32:33.125356Z","iopub.execute_input":"2025-01-02T18:32:33.125830Z","iopub.status.idle":"2025-01-02T18:32:48.014631Z","shell.execute_reply.started":"2025-01-02T18:32:33.125793Z","shell.execute_reply":"2025-01-02T18:32:48.013385Z"}},"outputs":[{"name":"stderr","text":"Processing Categories: 100%|██████████| 11/11 [00:00<00:00, 106062.86it/s]\nBuilding Image Annotations Dictionary: 100%|██████████| 669983/669983 [00:00<00:00, 1973788.56it/s]\nProcessing Annotations: 100%|██████████| 669983/669983 [00:04<00:00, 148759.98it/s]\nProcessing Images: 100%|██████████| 45891/45891 [00:00<00:00, 777392.41it/s]\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"### Category Check","metadata":{}},{"cell_type":"code","source":"def count_bounding_boxes(json_path):\n    \"\"\"\n    Conta il numero di bounding box per ogni categoria in un file COCO JSON.\n\n    Args:\n        json_path (str): Percorso del file JSON.\n\n    Returns:\n        list: Elenco di tuple con ID categoria, nome categoria e numero di bounding box.\n    \"\"\"\n    # Carica il file JSON\n    coco_data = load_json(json_path)\n\n    # Estrarre i dati principali\n    annotations = coco_data.get(\"annotations\", [])\n    categories = coco_data.get(\"categories\", [])\n\n    # Mappare id di categoria ai nomi delle categorie\n    category_id_to_name = {category[\"id\"]: category[\"name\"] for category in categories}\n\n    # Contare i bounding box per categoria\n    bbox_counts = defaultdict(int)\n    for annotation in annotations:\n        category_id = annotation[\"category_id\"]\n        bbox_counts[category_id] += 1\n\n    # Creare un elenco dei risultati\n    results = [\n        (cat_id, category_id_to_name.get(cat_id, \"Unknown\"), count)\n        for cat_id, count in bbox_counts.items()\n    ]\n    \n    # Ordinare i risultati in ordine decrescente per numero di bounding box\n    results.sort(key=lambda x: x[2], reverse=True)\n    \n    # Stampare i risultati\n    for cat_id, category_name, count in results:\n        print(f\"Categoria ID {cat_id} ('{category_name}'): {count} bounding box\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T18:32:48.016493Z","iopub.execute_input":"2025-01-02T18:32:48.016882Z","iopub.status.idle":"2025-01-02T18:32:48.024868Z","shell.execute_reply.started":"2025-01-02T18:32:48.016846Z","shell.execute_reply":"2025-01-02T18:32:48.023775Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"count_bounding_boxes(new_coco_json_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T18:32:48.026077Z","iopub.execute_input":"2025-01-02T18:32:48.026386Z","iopub.status.idle":"2025-01-02T18:32:50.635275Z","shell.execute_reply.started":"2025-01-02T18:32:48.026356Z","shell.execute_reply":"2025-01-02T18:32:50.633868Z"}},"outputs":[{"name":"stdout","text":"Categoria ID 6 ('Building'): 343313 bounding box\nCategoria ID 1 ('Passenger Vehicle'): 93827 bounding box\nCategoria ID 2 ('Truck'): 24582 bounding box\nCategoria ID 0 ('background'): 13691 bounding box\nCategoria ID 4 ('Maritime Vessel'): 5161 bounding box\nCategoria ID 5 ('Engineering Vehicle'): 4728 bounding box\nCategoria ID 9 ('Shipping Container'): 4558 bounding box\nCategoria ID 3 ('Railway Vehicle'): 3691 bounding box\nCategoria ID 8 ('Storage Tank'): 1743 bounding box\nCategoria ID 11 ('Aircraft'): 1561 bounding box\nCategoria ID 10 ('Pylon'): 415 bounding box\nCategoria ID 7 ('Helipad'): 136 bounding box\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# JSON to YOLO","metadata":{}},{"cell_type":"code","source":"def convert_json_to_yolo(json_path, images_dir, output_dir, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n    # Carica il file JSON\n    with open(json_path) as f:\n        data = json.load(f)\n\n    # Mappa le classi\n    class_mapping = {category['id']: category['name'] for category in data['categories']}\n    nc = len(class_mapping)  # Numero di classi\n\n    # Crea le cartelle per il dataset\n    train_dir = os.path.join(output_dir, 'train')\n    val_dir = os.path.join(output_dir, 'val')\n    test_dir = os.path.join(output_dir, 'test')\n    labels_dir = os.path.join(output_dir, 'labels')\n    \n    for dir_path in [train_dir, val_dir, test_dir, labels_dir]:\n        os.makedirs(dir_path, exist_ok=True)\n\n    # Dividi le immagini in training, validation, and test\n    images = data['images']\n    random.shuffle(images)\n    total_images = len(images)\n    \n    train_split = int(train_ratio * total_images)\n    val_split = int((train_ratio + val_ratio) * total_images)\n\n    train_images = images[:train_split]\n    val_images = images[train_split:val_split]\n    test_images = images[val_split:]\n\n    # Funzione per copiare le immagini in una cartella specifica\n    def copy_images(image_list, target_dir):\n        for image in tqdm(image_list, desc=f\"Copying images to {target_dir}\", unit=\"image\"):\n            src_path = os.path.join(images_dir, image['file_name'])\n            dst_path = os.path.join(target_dir, image['file_name'])\n            shutil.copy(src_path, dst_path)\n\n    # Copia le immagini nelle rispettive cartelle\n    copy_images(train_images, train_dir)\n    copy_images(val_images, val_dir)\n    copy_images(test_images, test_dir)\n\n    # Converte le annotazioni in formato YOLO e salva nei file di testo\n    def convert_annotations(image, annotations, target_dir):\n        image_id = image['id']\n        image_width = image['width']\n        image_height = image['height']\n        image_name = image['file_name']\n\n        label_file_path = os.path.join(target_dir, f\"{image_name.replace('.jpg', '.txt')}\")\n        label_dir = os.path.dirname(label_file_path)\n\n        # Crea la cartella se non esiste\n        os.makedirs(label_dir, exist_ok=True)\n\n        with open(label_file_path, 'w') as label_file:\n            for annotation in annotations:\n                if annotation['image_id'] == image_id:\n                    category_id = annotation['category_id']\n                    xmin, ymin, xmax, ymax = annotation['bbox']\n\n                    # Normalizza le coordinate\n                    x_center = (xmin + xmax) / 2 / image_width\n                    y_center = (ymin + ymax) / 2 / image_height\n                    width = (xmax - xmin) / image_width\n                    height = (ymax - ymin) / image_height\n\n                    # Scrivi nel file di annotazione\n                    label_file.write(f\"{category_id} {x_center} {y_center} {width} {height}\\n\")\n\n    # Converte le annotazioni per ogni immagine e le salva nelle cartelle appropriate\n    def process_images(image_list, target_dir, label_target_dir):\n        for image in tqdm(image_list, desc=f\"Converting annotations\", unit=\"image\"):\n            annotations = [annotation for annotation in data['annotations'] if annotation['image_id'] == image['id']]\n            convert_annotations(image, annotations, os.path.join(label_target_dir, target_dir))\n\n    # Processa le immagini per training, validation e test\n    process_images(train_images, 'train', labels_dir)\n    process_images(val_images, 'val', labels_dir)\n    process_images(test_images, 'test', labels_dir)\n\n    # Crea il file YAML per YOLO\n    yaml_content = f\"\"\"\n    path: {output_dir}\n    train: {train_dir}\n    val: {val_dir}\n    test: {test_dir}\n    nc: {nc}\n    names: {list(class_mapping.values())}\n    \"\"\"\n    with open(os.path.join(output_dir, 'dataset.yaml'), 'w') as yaml_file:\n        yaml_file.write(yaml_content.strip())\n\n    print(\"Conversione e split completati.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T18:32:50.638075Z","iopub.execute_input":"2025-01-02T18:32:50.638575Z","iopub.status.idle":"2025-01-02T18:32:50.658621Z","shell.execute_reply.started":"2025-01-02T18:32:50.638517Z","shell.execute_reply":"2025-01-02T18:32:50.657459Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"convert_json_to_yolo(\n    json_path=new_coco_json_pth,\n    images_dir=img_fldr,\n    output_dir=yolo_path, \n    train_ratio=0.8,\n    val_ratio=0.1,\n    test_ratio=0.1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T18:32:50.660104Z","iopub.execute_input":"2025-01-02T18:32:50.660522Z","iopub.status.idle":"2025-01-02T19:21:21.732650Z","shell.execute_reply.started":"2025-01-02T18:32:50.660406Z","shell.execute_reply":"2025-01-02T19:21:21.731629Z"}},"outputs":[{"name":"stderr","text":"Copying images to /kaggle/working/YOLO/train: 100%|██████████| 36712/36712 [00:51<00:00, 715.44image/s]\nCopying images to /kaggle/working/YOLO/val: 100%|██████████| 4589/4589 [00:06<00:00, 677.41image/s]\nCopying images to /kaggle/working/YOLO/test: 100%|██████████| 4590/4590 [00:06<00:00, 703.25image/s]\nConverting annotations: 100%|██████████| 36712/36712 [37:54<00:00, 16.14image/s]\nConverting annotations: 100%|██████████| 4589/4589 [04:44<00:00, 16.15image/s]\nConverting annotations: 100%|██████████| 4590/4590 [04:44<00:00, 16.14image/s]\n","output_type":"stream"},{"name":"stdout","text":"Conversione e split completati.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Nome del file zip da creare\nzip_file_name = \"YOLO_dataset.zip\"\n\n# Elenco di file e cartelle da includere nello zip\nitems_to_zip = [\n    \"YOLO/labels\",\n    \"YOLO/test\",\n    \"YOLO/train\",\n    \"YOLO/val\",\n    \"YOLO/dataset.yaml\",\n]\n\n# Funzione per aggiungere file e cartelle allo zip\ndef zip_folder(zipf, folder_path, base_folder=\"\"):\n    for root, _, files in os.walk(folder_path):\n        for file in files:\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, base_folder)\n            zipf.write(file_path, arcname)\n\n# Creazione dello zip\nwith zipfile.ZipFile(zip_file_name, 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n    for item in items_to_zip:\n        if os.path.exists(item):  # Verifica che il file o la cartella esista\n            if os.path.isdir(item):  # Se è una cartella, aggiungi tutto il contenuto\n                zip_folder(zipf, item, out_dataset_pth)\n            else:  # Se è un file, aggiungilo direttamente\n                zipf.write(item)\n        else:\n            print(f\"Elemento non trovato: {item}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T19:24:11.546615Z","iopub.execute_input":"2025-01-02T19:24:11.546998Z","iopub.status.idle":"2025-01-02T19:25:21.154079Z","shell.execute_reply.started":"2025-01-02T19:24:11.546965Z","shell.execute_reply":"2025-01-02T19:25:21.152818Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"# Azioni preliminari","metadata":{}},{"cell_type":"markdown","source":"### Copia il repository","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Cambia directory","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/yolov5","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Installa le dipendenze","metadata":{}},{"cell_type":"code","source":"!pip install -r requirements.txt    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Path","metadata":{}},{"cell_type":"code","source":"train_file = \"/kaggle/input/our-xview-dataset/YOLO_cfg/train.txt\"\nval_file = \"/kaggle/input/our-xview-dataset/YOLO_cfg/val.txt\"\ntest_file = \"/kaggle/input/our-xview-dataset/YOLO_cfg/test.txt\"\ndataset_yaml = \"/kaggle/input/our-xview-dataset/YOLO_cfg/xview_yolo.yaml\" # bisogna modificare i path nel file perchè non si trovano \n                                                                            # -> bisogna anche vedere se fare delle modifiche alle classi\n\n\n# path per la gestione del modello e dell'addestramento\nmodel_path = \"yolov5s.pt\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Network","metadata":{}},{"cell_type":"code","source":"class YoloModel(nn.Module):\n    \"\"\"\n    Classe YOLOv5 per definire il modello e la funzione di forward.\n    \"\"\"\n    def __init__(self, model_path=\"yolov5s.pt\"):\n        \"\"\"\n        Inizializza il modello YOLOv5.\n\n        Args:\n            model_path (str): Percorso ai pesi pre-addestrati YOLOv5.\n        \"\"\"\n        super(YoloModel, self).__init__()\n        self.model_path = model_path\n        self.model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)\n\n    def forward(self, images):\n        \"\"\"\n        Esegue la predizione sul batch di immagini.\n\n        Args:\n            images (torch.Tensor): Batch di immagini di input.\n\n        Returns:\n            torch.Tensor: Risultati delle predizioni.\n        \"\"\"\n        return self.model(images)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T18:52:25.162903Z","iopub.execute_input":"2024-12-08T18:52:25.163250Z","iopub.status.idle":"2024-12-08T18:52:25.174329Z","shell.execute_reply.started":"2024-12-08T18:52:25.163197Z","shell.execute_reply":"2024-12-08T18:52:25.173152Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"yolo_model = YoloModel() # non è necessario segnalare il numero di classi perchè sono prese direttamente dal file .yaml","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T18:52:25.175815Z","iopub.execute_input":"2024-12-08T18:52:25.176187Z","iopub.status.idle":"2024-12-08T18:52:33.217079Z","shell.execute_reply.started":"2024-12-08T18:52:25.176117Z","shell.execute_reply":"2024-12-08T18:52:33.215988Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## per addestrare il modello\n### python train.py --img 640 --epochs 3 --data dataset.yaml --weights yolov5s.pt","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    \"\"\"\n    Classe per addestrare un modello YOLOv5.\n    \"\"\"\n    def __init__(self, model, dataset_yaml, optimizer, img_size=640, batch_size=16, epochs=50, cache=\"ram\", save_best_only=True):\n        \"\"\"\n        Inizializza il Trainer per YOLOv5.\n\n        Args:\n            model (YoloModel): Istanza del modello YOLOv5.\n            dataset_yaml (str): Percorso al file di configurazione del dataset.\n            optimizer (str): Ottimizzatore (e.g., 'Adam', 'SGD').\n            img_size (int): Dimensione delle immagini di input.\n            batch_size (int): Dimensione del batch per l'addestramento.\n            epochs (int): Numero di epoche.\n            cache (str): Tipo di caching ('ram' o 'disk').\n            save_best_only (bool): Se True, salva solo il modello con la migliore performance di validazione.\n        \"\"\"\n        self.model = model\n        self.dataset_yaml = dataset_yaml\n        self.img_size = img_size\n        self.batch_size = batch_size\n        self.epochs = epochs\n        self.cache = cache\n        self.optimizer = optimizer\n        self.save_best_only = save_best_only\n        self.best_val_loss = float('inf')  # Inizializza la miglior loss di validazione come infinita\n\n    def train(self): \n        \"\"\"\n        Avvia l'addestramento del modello utilizzando YOLOv5.\n        \"\"\"\n        print(\"Inizio addestramento...\")\n        for epoch in range(self.epochs):\n            # Definisci il comando per l'addestramento\n            command = (\n                f\"python train.py --img {self.img_size} --batch-size {self.batch_size} \"\n                f\"--epochs {self.epochs} --optimizer {self.optimizer} \"\n                f\"--data {self.dataset_yaml} \"\n                f\"--weights {self.model.model_path} --cache {self.cache} \"\n                f\"--save-period 1 --project runs/train --name {self.model.name} --exist-ok\"\n            )\n            try:\n                # Avvia il processo di training e monitora la validazione\n                subprocess.run(command, check=True, shell=True)\n                print(f\"Epoch {epoch+1}/{self.epochs} completata.\")\n            except subprocess.CalledProcessError as e:\n                print(f\"Errore durante l'addestramento, Epoch {epoch+1}/{self.epochs} fallita. Dettagli: {e}\")\n                break\n\n            # A questo punto, possiamo eseguire la validazione per monitorare i progressi\n            val_loss = self.validate()\n\n            # Salva il miglior modello sulla base della validazione\n            if self.save_best_only and val_loss < self.best_val_loss:\n                self.best_val_loss = val_loss\n                self.save_best_model()\n\n        print(\"Addestramento completato.\")\n\n    def validate(self):\n        \"\"\"\n        Valida il modello sui dati di test e ritorna la loss di validazione.\n\n        Returns:\n            float: La loss di validazione.\n        \"\"\"\n        print(\"Inizio validazione...\")\n        command = f\"python val.py --data {self.dataset_yaml} --weights {self.model.model_path} --img {self.img_size}\"\n        result = subprocess.run(command, shell=True, capture_output=True, text=True)\n\n        # Estrai la loss di validazione dal log di output\n        for line in result.stdout.splitlines():\n            if \"val_loss\" in line:  # Trova la linea con la validazione della loss\n                val_loss = float(line.split()[-1])  # Assumendo che l'ultima colonna contenga la loss\n                print(f\"Loss di validazione: {val_loss}\")\n                return val_loss\n        \n        print(\"Non è stato possibile estrarre la loss di validazione.\")\n        return float('inf')  # Se non riesci a trovare la loss, ritorna infinito\n\n    def save_best_model(self):\n        \"\"\"\n        Salva il miglior modello sulla base della validazione.\n        \"\"\"\n        print(f\"Salvataggio del miglior modello con perdita di validazione: {self.best_val_loss}\")\n        best_model_path = f\"best_model_{self.best_val_loss:.4f}.pt\"\n        # Comando per salvare il modello\n        command = f\"cp {self.model.model_path} {best_model_path}\"\n        subprocess.run(command, shell=True, check=True)\n        print(f\"Miglior modello salvato in {best_model_path}.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T18:52:33.218305Z","iopub.execute_input":"2024-12-08T18:52:33.218809Z","iopub.status.idle":"2024-12-08T18:52:33.226446Z","shell.execute_reply.started":"2024-12-08T18:52:33.218775Z","shell.execute_reply":"2024-12-08T18:52:33.225394Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = Trainer(\n    model=yolo_model,\n    dataset_yaml=dataset_yaml,\n    optimizer = \"Adam\",\n    img_size=640,\n    batch_size=16,\n    epochs=50,\n    cache=\"ram\"\n)\n\n# 4. Avvia il training\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T18:52:33.227813Z","iopub.execute_input":"2024-12-08T18:52:33.228119Z","iopub.status.idle":"2024-12-08T18:52:54.832174Z","shell.execute_reply.started":"2024-12-08T18:52:33.228088Z","shell.execute_reply":"2024-12-08T18:52:54.830931Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# YoloV11","metadata":{}},{"cell_type":"code","source":"%pip install ultralytics\nimport ultralytics\nultralytics.checks()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T18:07:35.374047Z","iopub.execute_input":"2025-01-02T18:07:35.375347Z","iopub.status.idle":"2025-01-02T18:07:54.442142Z","shell.execute_reply.started":"2025-01-02T18:07:35.375267Z","shell.execute_reply":"2025-01-02T18:07:54.441022Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.56 🚀 Python-3.10.14 torch-2.4.0+cpu CPU (Intel Xeon 2.20GHz)\nSetup complete ✅ (4 CPUs, 31.4 GB RAM, 6037.6/8062.4 GB disk)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# Load a model\nmodel = YOLO('yolo11n.pt')  # load a pretrained model (recommended for training)\n\n# Use the model\nresults = model.train(data='coco8.yaml', epochs=3)  # train the model\nresults = model.val()  # evaluate model performance on the validation set\nresults = model('https://ultralytics.com/images/bus.jpg')  # predict on an image","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}